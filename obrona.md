# ğŸ“ OBRONA PROJEKTU ANFIS - Kompletny Przewodnik

## Spis treÅ›ci

1. [Podstawowe pytania o projekt](#1-podstawowe-pytania-o-projekt)
2. [Pytania o ANFIS](#2-pytania-o-anfis)
3. [Zadania do wykonania](#3-zadania-do-wykonania)
4. [Mapa projektu - gdzie co jest](#4-mapa-projektu---gdzie-co-jest)
5. [PorÃ³wnanie ANFIS vs modele klasyczne](#5-porÃ³wnanie-anfis-vs-modele-klasyczne)

---

## 1. Podstawowe pytania o projekt

### ğŸ”¹1.1 Co to jest model TSK (Takagi-Sugeno-Kang)?

**OdpowiedÅº:** Model TSK to rodzaj systemu rozmytego, w ktÃ³rym **konsekwent reguÅ‚y jest funkcjÄ… liniowÄ…** zamiast tradycyjnego zbioru rozmytego. W klasycznych systemach rozmytych (Mamdani) wynik reguÅ‚y to zbiÃ³r rozmyty (np. "temperatura jest WYSOKA"), natomiast w TSK wynik to konkretna wartoÅ›Ä‡ liczbowa obliczona ze wzoru liniowego. DziÄ™ki temu model TSK jest Å‚atwiejszy do optymalizacji metodami gradientowymi i daje precyzyjne wyniki numeryczne, co czyni go idealnym do zastosowaÅ„ w sieciach neuronowych jak ANFIS.

**ReguÅ‚a TSK pierwszego rzÄ™du:**

```
JEÅšLI xâ‚ jest Aâ‚ ORAZ xâ‚‚ jest Aâ‚‚ ORAZ ... xâ‚™ jest Aâ‚™
TO y = wâ‚€ + wâ‚Â·xâ‚ + wâ‚‚Â·xâ‚‚ + ... + wâ‚™Â·xâ‚™
```

**Gdzie w kodzie:** [anfis.py](anfis.py#L1-L10) - komentarz na poczÄ…tku pliku oraz `DefuzzLayer` (linie 232-264)

```python
# W DefuzzLayer.call():
y = tf.matmul(x, self.CP_weight) + self.CP_bias  # f_i(x) = xÂ·W_i + b_i
return w_norm * y  # WaÅ¼ona kombinacja
```

**Zalety TSK:**

- WyjÅ›cie jest gÅ‚adkÄ… funkcjÄ… (Å‚atwiejsze w uczeniu)
- MoÅ¼e aproksymowaÄ‡ dowolnÄ… funkcjÄ™ ciÄ…gÅ‚Ä…
- Nadaje siÄ™ zarÃ³wno do klasyfikacji jak i regresji

---

### ğŸ”¹ 1.2 Co to jest funkcja przynaleÅ¼noÅ›ci (Membership Function)?

**OdpowiedÅº:** Funkcja przynaleÅ¼noÅ›ci Î¼(x) okreÅ›la **stopieÅ„ przynaleÅ¼noÅ›ci** elementu x do zbioru rozmytego - czyli "jak bardzo" dany element pasuje do danej kategorii. W przeciwieÅ„stwie do logiki klasycznej (gdzie element albo naleÅ¼y, albo nie naleÅ¼y do zbioru), logika rozmyta pozwala na czÄ™Å›ciowÄ… przynaleÅ¼noÅ›Ä‡ wyraÅ¼onÄ… liczbÄ… z przedziaÅ‚u [0, 1]. Na przykÅ‚ad, wino o zawartoÅ›ci alkoholu 11% moÅ¼e mieÄ‡ przynaleÅ¼noÅ›Ä‡ 0.7 do zbioru "mocne" i 0.3 do zbioru "Å›rednie" - to pozwala modelowaÄ‡ niepewnoÅ›Ä‡ i pÅ‚ynne przejÅ›cia miÄ™dzy kategoriami.

**WartoÅ›ci Î¼(x) âˆˆ [0, 1]:**

- 0 = element w ogÃ³le nie naleÅ¼y do zbioru
- 1 = element w peÅ‚ni naleÅ¼y do zbioru
- wartoÅ›ci poÅ›rednie = czÄ™Å›ciowa przynaleÅ¼noÅ›Ä‡ (np. 0.7 = "raczej naleÅ¼y")

**W projekcie uÅ¼ywamy funkcji Gaussa:**

$$\mu(x) = e^{-\frac{1}{2}\left(\frac{x - c}{\sigma}\right)^2}$$

Gdzie:

- **c** = centrum (mean) - punkt maksymalnej przynaleÅ¼noÅ›ci
- **Ïƒ** = szerokoÅ›Ä‡ (sigma) - jak szybko spada przynaleÅ¼noÅ›Ä‡

**Gdzie w kodzie:** [anfis.py](anfis.py#L158-L200) - klasa `FuzzyLayer`

```python
def call(self, x):
    x = tf.expand_dims(x, axis=1)                       # (B, 1, n)
    sigma_eff = tf.maximum(self.sigma, self.eps)        # zabezpieczenie przed dzieleniem przez 0
    z = (x - self.c[None, :, :]) / (sigma_eff[None, :, :] + self.eps)
    mu = tf.exp(-0.5 * tf.square(z))                    # Gaussowska MF
    return tf.clip_by_value(mu, 1e-8, 1.0)
```

**Wizualizacja:** Wykresy funkcji przynaleÅ¼noÅ›ci sÄ… zapisywane do `results/membership_functions_*.png`

---

### ğŸ”¹ 1.3 Co to jest preprocessing (przetwarzanie wstÄ™pne)?

**OdpowiedÅº:** Preprocessing to **przygotowanie surowych danych** przed uczeniem modelu - jest to kluczowy etap, ktÃ³ry bezpoÅ›rednio wpÅ‚ywa na jakoÅ›Ä‡ wynikÃ³w. Surowe dane czÄ™sto majÄ… rÃ³Å¼ne skale (np. pH 0-14, alkohol 8-15%), zawierajÄ… braki lub sÄ… w nieodpowiednim formacie, co utrudnia uczenie modeli. Preprocessing ujednolica dane, usuwa szum i przeksztaÅ‚ca je do postaci optymalnej dla algorytmÃ³w uczenia maszynowego - bez tego modele mogÅ‚yby faworyzowaÄ‡ cechy o wiÄ™kszych wartoÅ›ciach lub w ogÃ³le nie zbiegaÄ‡.

**GÅ‚Ã³wne kroki preprocessingu:**

1. **NormalizacjÄ™/StandaryzacjÄ™** - sprowadzenie cech do porÃ³wnywalnej skali (Å›rednia=0, odchylenie=1)
2. **PodziaÅ‚ danych** na zbiÃ³r treningowy (80%) i testowy (20%) - Å¼eby uczciwie oceniÄ‡ model
3. **TransformacjÄ™ etykiet** (np. binaryzacja jakoÅ›ci wina: >5 = dobre, â‰¤5 = sÅ‚abe)

**Gdzie w kodzie:** [data_preprocessing.py](data_preprocessing.py) - caÅ‚y plik

**Co robi preprocessing w projekcie:**

| Krok                   | Opis                              | Kod         |
| ---------------------- | --------------------------------- | ----------- |
| 1. Wczytanie CSV       | `pd.read_csv()`                   | linia 31-32 |
| 2. Binaryzacja jakoÅ›ci | `quality > 5 â†’ 1, else 0`         | linia 44    |
| 3. PodziaÅ‚ train/test  | `train_test_split(test_size=0.2)` | linia 57-59 |
| 4. StandardScaler      | `Î¼=0, Ïƒ=1` dla kaÅ¼dej cechy       | linia 61-63 |
| 5. Zapis do .npy       | `np.save()`                       | linia 65-72 |

```python
# Binaryzacja jakoÅ›ci wina
wine_data['quality_binary'] = (wine_data['quality'] > 5).astype(int)

# Standaryzacja (Å›rednia=0, odchylenie=1)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)  # dopasuj i transformuj
X_test = scaler.transform(X_test)        # tylko transformuj (te same parametry!)
```

**WAÅ»NE:** Ten sam preprocessing musi byÄ‡ uÅ¼yty dla ANFIS i modeli porÃ³wnawczych!

---

### ğŸ”¹ 1.4 Co to jest ANFIS?

**OdpowiedÅº:** ANFIS (Adaptive Neuro-Fuzzy Inference System) to **hybrydowa architektura** Å‚Ä…czÄ…ca zalety dwÃ³ch podejÅ›Ä‡: logiki rozmytej i sieci neuronowych. System rozmyty zapewnia interpretowalnoÅ›Ä‡ - moÅ¼emy odczytaÄ‡ reguÅ‚y typu "JEÅšLI alkohol jest WYSOKI i kwasowoÅ›Ä‡ jest NISKA TO wino jest DOBRE", podczas gdy sieÄ‡ neuronowa automatycznie uczy siÄ™ optymalnych parametrÃ³w tych reguÅ‚ z danych. ANFIS Å‚Ä…czy wiÄ™c "biaÅ‚Ä… skrzynkÄ™" (zrozumiaÅ‚e reguÅ‚y) z mocÄ… uczenia "czarnej skrzynki" (sieci neuronowe), dajÄ…c model ktÃ³ry jest zarÃ³wno skuteczny jak i wyjaÅ›nialny.

**PoÅ‚Ä…czenie dwÃ³ch Å›wiatÃ³w:**

- **System wnioskowania rozmytego** (Fuzzy Inference System) - tworzy zrozumiaÅ‚e reguÅ‚y IF-THEN
- **SieÄ‡ neuronowa** - automatycznie optymalizuje parametry funkcji przynaleÅ¼noÅ›ci i wagi reguÅ‚

**5 warstw ANFIS:**

```
WejÅ›cie â†’ [1.Fuzzy] â†’ [2.Rule] â†’ [3.Norm] â†’ [4.Defuzz] â†’ [5.Sum] â†’ WyjÅ›cie
```

| Warstwa | Nazwa          | Funkcja                        | W kodzie         |
| ------- | -------------- | ------------------------------ | ---------------- |
| 1       | FuzzyLayer     | Oblicza Î¼(x) dla kaÅ¼dej MF     | anfis.py:158-200 |
| 2       | RuleLayer      | Iloczyn (T-norma AND)          | anfis.py:203-221 |
| 3       | NormLayer      | Normalizacja wag: wÌ„áµ¢ = wáµ¢/Î£wâ±¼  | anfis.py:224-231 |
| 4       | DefuzzLayer    | Konsekwent TSK: fáµ¢ = xÂ·Wáµ¢ + báµ¢ | anfis.py:234-264 |
| 5       | SummationLayer | Suma: y = Î£wÌ„áµ¢Â·fáµ¢               | anfis.py:267-273 |

**Gdzie w kodzie:** [anfis.py](anfis.py) - caÅ‚y plik definiuje architekturÄ™

---

### ğŸ”¹ 1.5 Jak dziaÅ‚a "losowa linia" (inicjalizacja wag)?

**OdpowiedÅº:** Przy tworzeniu modelu wszystkie parametry (wagi) sÄ… inicjalizowane **losowo** z okreÅ›lonych rozkÅ‚adÃ³w - to kluczowe dla prawidÅ‚owego uczenia. GdybyÅ›my zainicjowali wszystkie wagi tak samo (np. zerami), to wszystkie neurony/reguÅ‚y uczyÅ‚yby siÄ™ tego samego - nie byÅ‚oby rÃ³Å¼norodnoÅ›ci. Losowa inicjalizacja "Å‚amie symetriÄ™" i pozwala rÃ³Å¼nym czÄ™Å›ciom sieci specjalizowaÄ‡ siÄ™ w rÃ³Å¼nych wzorcach.

**W ANFIS inicjalizujemy losowo:**

1. **Centra funkcji przynaleÅ¼noÅ›ci (c)** - gdzie na osi X jest "Å›rodek" kaÅ¼dej funkcji Gaussa
2. **SzerokoÅ›ci funkcji przynaleÅ¼noÅ›ci (Ïƒ)** - jak "szerokie" sÄ… funkcje Gaussa
3. **Wagi konkluzji (CP_weight, CP_bias)** - parametry reguÅ‚ TSK

**Dlaczego uÅ¼ywamy seed=42?** Ustawienie ziarna generatora losowego (seed) zapewnia **powtarzalnoÅ›Ä‡** - za kaÅ¼dym razem gdy uruchomimy trening, dostaniemy te same "losowe" wartoÅ›ci poczÄ…tkowe. DziÄ™ki temu eksperymenty sÄ… odtwarzalne i moÅ¼emy porÃ³wnywaÄ‡ wyniki.

**Gdzie w kodzie:** [anfis.py](anfis.py#L178-L190)

```python
# FuzzyLayer - parametry funkcji przynaleÅ¼noÅ›ci
self.c = self.add_weight(
    name="c",
    shape=(self.m, self.n),
    initializer=tf.keras.initializers.RandomUniform(minval=-1.5, maxval=1.5, seed=42),
    trainable=True,
)
self.sigma = self.add_weight(
    name="sigma",
    shape=(self.m, self.n),
    initializer=tf.keras.initializers.RandomUniform(minval=0.5, maxval=1.5, seed=42),
    trainable=True,
)
```

**Dlaczego losowo?**

- Przerywa symetriÄ™ (rÃ³Å¼ne neurony uczÄ… siÄ™ rÃ³Å¼nych cech)
- `seed=42` zapewnia powtarzalnoÅ›Ä‡ eksperymentÃ³w
- Zakres `-1.5 do 1.5` dla centrÃ³w (dane sÄ… znormalizowane do ~Â±3)
- Zakres `0.5 do 1.5` dla sigma (rozsÄ…dna szerokoÅ›Ä‡ MF)

---

## 2. Pytania o ANFIS

### ğŸ”¹ 1.6 Co to jest walidacja krzyÅ¼owa (cross-validation)?

**OdpowiedÅº:** K-krotna walidacja krzyÅ¼owa to technika oceny modelu, ktÃ³ra pozwala wiarygodnie oszacowaÄ‡ jak model bÄ™dzie dziaÅ‚aÅ‚ na nowych danych. Problem z pojedynczym podziaÅ‚em train/test polega na tym, Å¼e wynik zaleÅ¼y od "szczÄ™Å›cia" - ktÃ³ry zestaw danych trafiÅ‚ do testu. Cross-validation rozwiÄ…zuje to przez wielokrotne testowanie: kaÅ¼da prÃ³bka jest dokÅ‚adnie raz w zbiorze testowym, wiÄ™c dostajemy stabilnÄ… ocenÄ™ uÅ›rednionÄ… z K eksperymentÃ³w.

**Jak dziaÅ‚a (dla K=5):**

1. Dane dzielimy na 5 rÃ³wnych czÄ™Å›ci (foldÃ³w)
2. 5 razy trenujemy model: za kaÅ¼dym razem 4 czÄ™Å›ci to trening, 1 czÄ™Å›Ä‡ to test
3. UÅ›redniamy wyniki z 5 testÃ³w â†’ dostajemy wiarygodnÄ… ocenÄ™ Â± odchylenie standardowe

**Zalety:**

- Wykorzystuje 100% danych zarÃ³wno do treningu jak i testu (kaÅ¼da prÃ³bka jest raz testowana)
- Zmniejsza wariancjÄ™ oszacowania bÅ‚Ä™du - wynik nie zaleÅ¼y od losowego podziaÅ‚u
- Wykrywa overfitting - jeÅ›li model dobrze dziaÅ‚a na treningu ale sÅ‚abo na CV, to siÄ™ przeuczyÅ‚

**Gdzie w kodzie:** [train_anfis.py](train_anfis.py#L507-L572) - funkcja `cross_validate_anfis()`

```python
def cross_validate_anfis(n_memb=2, batch_size=32, dataset="all", n_splits=5, epochs=10):
    # UÅ¼ywa StratifiedKFold dla klasyfikacji (zachowuje proporcje klas)
    splitter = KFold(n_splits=n_splits, shuffle=True, random_state=42) \
        if dataset == "concrete" else StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)

    for fold, (tr_idx, va_idx) in enumerate(splitter.split(X, y), 1):
        # Trenuj na tr_idx, testuj na va_idx
        ...
```

**Wyniki CV:** zapisywane do `results/anfis_*_cv.json`

---

### ğŸ”¹ 1.7 Co mierzy Accuracy?

**OdpowiedÅº:** Accuracy (dokÅ‚adnoÅ›Ä‡) mierzy **procent poprawnych klasyfikacji** - czyli ile razy model trafnie przewidziaÅ‚ klasÄ™ spoÅ›rÃ³d wszystkich prÃ³bek. Jest to najprostsza i najbardziej intuicyjna metryka: jeÅ›li accuracy = 75%, oznacza to Å¼e model poprawnie sklasyfikowaÅ‚ 75 na 100 prÃ³bek. Accuracy odpowiada na pytanie "jak czÄ™sto model ma racjÄ™?", ale nie rozrÃ³Å¼nia miÄ™dzy typami bÅ‚Ä™dÃ³w (faÅ‚szywe alarmy vs przeoczenia).

**WzÃ³r:**
$$\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN} = \frac{\text{poprawne predykcje}}{\text{wszystkie prÃ³bki}}$$

**SkÅ‚adniki (macierz pomyÅ‚ek):**

- TP = True Positive - model powiedziaÅ‚ "dobre wino" i miaÅ‚ racjÄ™
- TN = True Negative - model powiedziaÅ‚ "sÅ‚abe wino" i miaÅ‚ racjÄ™
- FP = False Positive - model powiedziaÅ‚ "dobre" ale wino byÅ‚o sÅ‚abe (faÅ‚szywy alarm)
- FN = False Negative - model powiedziaÅ‚ "sÅ‚abe" ale wino byÅ‚o dobre (przeoczenie)

**Gdzie w kodzie:** [train_anfis.py](train_anfis.py#L117-L121)

```python
anfis_model.model.compile(
    optimizer=tf.keras.optimizers.Nadam(learning_rate=0.001),
    loss="binary_crossentropy",
    metrics=["accuracy"]  # <- tutaj definiujemy metrykÄ™
)
```

**Wady Accuracy:**

- MylÄ…ca przy niezbalansowanych klasach (np. 90% klasy A â†’ model moÅ¼e zawsze zgadywaÄ‡ A i mieÄ‡ 90% accuracy)

---

### ğŸ”¹1.8 Co mierzy ROC AUC?

**OdpowiedÅº:** ROC AUC (Area Under Receiver Operating Characteristic Curve) mierzy **zdolnoÅ›Ä‡ modelu do rozrÃ³Å¼niania klas** - czyli jak dobrze model potrafi oddzieliÄ‡ pozytywne przykÅ‚ady od negatywnych. WyobraÅº sobie, Å¼e model daje kaÅ¼demu winu "score" od 0 do 1 - ROC AUC mÃ³wi, jak czÄ™sto wino dobre dostaje wyÅ¼szy score niÅ¼ wino sÅ‚abe. AUC = 0.85 oznacza, Å¼e w 85% przypadkÃ³w losowo wybrane dobre wino bÄ™dzie miaÅ‚o wyÅ¼szy score niÅ¼ losowo wybrane sÅ‚abe wino.

**Dlaczego AUC a nie Accuracy?** Bo AUC nie zaleÅ¼y od progu (czy klasyfikujemy jako "dobre" przy score > 0.5, > 0.3 czy > 0.7) - mierzy ogÃ³lnÄ… jakoÅ›Ä‡ rankingu, nie konkretnych decyzji.

**Interpretacja wartoÅ›ci:**

- AUC = 1.0 â†’ idealny klasyfikator (wszystkie dobre majÄ… wyÅ¼szy score niÅ¼ wszystkie sÅ‚abe)
- AUC = 0.5 â†’ losowy klasyfikator (jak rzut monetÄ… - model nic nie wie)
- AUC < 0.5 â†’ gorszy niÅ¼ losowy (model myli klasy - odwrÃ³Ä‡ predykcje!)
- **AUC > 0.8** â†’ dobry model, **AUC > 0.9** â†’ bardzo dobry model

**Zalety AUC:**

- Nie zaleÅ¼y od progu klasyfikacji - ocenia model caÅ‚oÅ›ciowo
- DziaÅ‚a dobrze dla niezbalansowanych danych (np. 90% jednej klasy)
- Mierzy jakoÅ›Ä‡ rankingu, nie tylko binarnych decyzji

**Gdzie w kodzie:** [train_comparison_models.py](train_comparison_models.py#L175)

```python
from sklearn.metrics import roc_auc_score
results['nn'] = {
    ...
    "roc_auc": float(roc_auc_score(y_test_r, y_proba)),
}
```

---

### ğŸ”¹ 1.9 Co mierzy MSE / MAE?

**OdpowiedÅº:** MSE i MAE to metryki dla zadaÅ„ regresji, ktÃ³re mierzÄ… **Å›redni bÅ‚Ä…d predykcji** - czyli jak bardzo wartoÅ›ci przewidziane przez model rÃ³Å¼niÄ… siÄ™ od prawdziwych wartoÅ›ci.

**MSE (Mean Squared Error) - Åšredni BÅ‚Ä…d Kwadratowy:**
MSE oblicza Å›redniÄ… z kwadratÃ³w rÃ³Å¼nic miÄ™dzy predykcjÄ… a rzeczywistoÅ›ciÄ…. PoniewaÅ¼ bÅ‚Ä™dy sÄ… podnoszone do kwadratu, duÅ¼e bÅ‚Ä™dy sÄ… karane znacznie mocniej niÅ¼ maÅ‚e - bÅ‚Ä…d 10 MPa daje karÄ™ 100, ale bÅ‚Ä…d 2 MPa daje karÄ™ tylko 4. To sprawia, Å¼e MSE jest wraÅ¼liwe na wartoÅ›ci odstajÄ…ce (outliers) i "zmusza" model do unikania duÅ¼ych pomyÅ‚ek.

$$\text{MSE} = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2$$

**MAE (Mean Absolute Error) - Åšredni BÅ‚Ä…d BezwzglÄ™dny:**
MAE oblicza Å›redniÄ… z wartoÅ›ci bezwzglÄ™dnych rÃ³Å¼nic - kaÅ¼dy bÅ‚Ä…d jest traktowany proporcjonalnie do jego wielkoÅ›ci. BÅ‚Ä…d 10 MPa jest karany 5x mocniej niÅ¼ bÅ‚Ä…d 2 MPa (a nie 25x jak w MSE). MAE jest bardziej "sprawiedliwe" i Å‚atwiejsze do interpretacji - jeÅ›li MAE = 5 MPa, to Å›rednio model myli siÄ™ o 5 MPa.

$$\text{MAE} = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|$$

**PorÃ³wnanie - kiedy co uÅ¼ywaÄ‡:**

| Metryka | Co mierzy               | WraÅ¼liwoÅ›Ä‡ na outliers      | Interpretacja             |
| ------- | ----------------------- | --------------------------- | ------------------------- |
| **MSE** | Åšredni kwadrat bÅ‚Ä™du    | Wysoka (karze duÅ¼e bÅ‚Ä™dy Â²) | Trudniejsza (jednostkiÂ²)  |
| **MAE** | Åšredni bÅ‚Ä…d bezwzglÄ™dny | Niska (rÃ³wno traktuje)      | Åatwa (te same jednostki) |

**PrzykÅ‚ad:** JeÅ›li przewidujemy wytrzymaÅ‚oÅ›Ä‡ betonu i MAE = 4.5 MPa, to Å›rednio mylimy siÄ™ o 4.5 megapaskala.

**Gdzie w kodzie:** [train_anfis.py](train_anfis.py#L109-L115)

```python
if dataset == "concrete":
    anfis_model.model.compile(
        optimizer=tf.keras.optimizers.Nadam(learning_rate=0.001),
        loss="mean_squared_error",  # MSE jako funkcja straty
        metrics=["mae"]              # MAE jako metryka
    )
```

---

### ğŸ”¹1.10 Czym rÃ³Å¼ni siÄ™ hybrydowe uczenie ANFIS od uczenia standardowego?

**OdpowiedÅº:** GÅ‚Ã³wna rÃ³Å¼nica polega na tym, **jak trenowane sÄ… dwa rodzaje parametrÃ³w** w ANFIS: parametry przeslanki (premise) - czyli centra i szerokoÅ›ci funkcji przynaleÅ¼noÅ›ci, oraz parametry konkluzji (consequent) - czyli wagi w regule TSK.

**Uczenie hybrydowe (klasyczny ANFIS Janga):** Rozdziela trening na dwie fazy w kaÅ¼dej epoce. Najpierw zamraÅ¼a parametry przeslanki i optymalizuje konkluzje metodÄ… najmniejszych kwadratÃ³w (LSE) - to jest szybkie bo ma rozwiÄ…zanie analityczne. Potem zamraÅ¼a konkluzje i uczy przesÅ‚anki gradientem. To przyspiesza zbieÅ¼noÅ›Ä‡, bo LSE znajduje optymalne konkluzje w jednym kroku.

**Uczenie standardowe (uÅ¼ywane w tym projekcie):** Trenuje wszystkie parametry jednoczeÅ›nie zwykÅ‚ym gradientem (backpropagation). Jest prostsze w implementacji (uÅ¼ywamy Keras/TensorFlow), ale moÅ¼e byÄ‡ wolniejsze. WspÃ³Å‚czesne optymalizatory (Adam, Nadam) czÄ™Å›ciowo niwelujÄ… tÄ™ rÃ³Å¼nicÄ™.

| Aspekt                | Standardowe (ten projekt)        | Hybrydowe (klasyczne)        |
| --------------------- | -------------------------------- | ---------------------------- |
| **Co trenuje**        | Wszystkie parametry jednoczeÅ›nie | Rozdziela premise/consequent |
| **Metoda premise**    | Gradient descent                 | Gradient descent             |
| **Metoda consequent** | Gradient descent                 | **Least Squares Estimation** |
| **Implementacja**     | Prosta (gotowe Keras)            | Bardziej zÅ‚oÅ¼ona             |
| **ZbieÅ¼noÅ›Ä‡**         | Wolniejsza (wiÄ™cej epok)         | Szybsza                      |

**W tym projekcie:** UÅ¼ywamy **standardowego uczenia (end-to-end backpropagation)** przez TensorFlow/Keras, ktÃ³re trenuje wszystkie parametry jednoczeÅ›nie metodÄ… gradientowÄ….

**Gdzie w kodzie:** [anfis.py](anfis.py#L22-L55) - model jest zwykÅ‚Ä… sieciÄ… Keras

```python
# Standardowe uczenie - wszystko przez backpropagation
self.model = tf.keras.Model(inputs=[x_in], outputs=[out], name=model_name)
# Wagi premise (c, sigma) i consequent (CP_weight, CP_bias) sÄ… wszystkie trainable=True
```

---

### ğŸ”¹1.11 Czym ANFIS rÃ³Å¼ni siÄ™ od sieci MLP?

**OdpowiedÅº:** NajwaÅ¼niejsza rÃ³Å¼nica to **interpretowalnoÅ›Ä‡**: ANFIS moÅ¼na "przeczytaÄ‡" jako zbiÃ³r reguÅ‚ IF-THEN zrozumiaÅ‚ych dla czÅ‚owieka, podczas gdy MLP to "czarna skrzynka" gdzie wagi nie majÄ… intuicyjnego znaczenia. W ANFIS wiesz, Å¼e "JEÅšLI alkohol jest WYSOKI i kwasowoÅ›Ä‡ jest NISKA TO wino jest dobre" - w MLP masz tylko macierz liczb.

**Druga rÃ³Å¼nica to sposÃ³b \u0142Ä…czenia informacji:** ANFIS uÅ¼ywa iloczynu (T-norma AND) do kombinowania wejÅ›Ä‡, co odpowiada logicznemu "ORAZ" - wszystkie warunki muszÄ… byÄ‡ speÅ‚nione. MLP uÅ¼ywa sumy waÅ¼onej, gdzie rÃ³Å¼ne cechy mogÄ… siÄ™ kompensowaÄ‡.

**Trzecia rÃ³Å¼nica to eksplozja zÅ‚oÅ¼onoÅ›ci:** W ANFIS liczba reguÅ‚ roÅ›nie wykÅ‚adniczo z liczbÄ… cech - dla 11 cech i 2 funkcji przynaleÅ¼noÅ›ci mamy 2^11 = 2048 reguÅ‚. W MLP moÅ¼emy mieÄ‡ dowolnÄ… liczbÄ™ neuronÃ³w niezaleÅ¼nie od wejÅ›Ä‡.

| Cecha                 | ANFIS                              | MLP (Multi-Layer Perceptron)     |
| --------------------- | ---------------------------------- | -------------------------------- |
| **InterpretowalnoÅ›Ä‡** | âœ… Wysoka (reguÅ‚y IF-THEN)         | âŒ Niska (czarna skrzynka)       |
| **Struktura**         | StaÅ‚a (5 warstw, wynika z logiki)  | Dowolna liczba warstw/neuronÃ³w   |
| **Funkcje aktywacji** | Gaussowskie funkcje przynaleÅ¼noÅ›ci | ReLU, sigmoid, tanh              |
| **ÅÄ…czenie wejÅ›Ä‡**    | Iloczyn (T-norma "ORAZ")           | Suma waÅ¼ona                      |
| **Konsekwent**        | Funkcja liniowa TSK                | Dowolna nieliniowa transformacja |
| **ZÅ‚oÅ¼onoÅ›Ä‡**         | n_memb^n_features reguÅ‚            | Konfigurowalana                  |

**PrzykÅ‚ad eksplozji reguÅ‚:**

- 11 cech Ã— 2 MF = 2^11 = **2,048 reguÅ‚** (zarzÄ…dzalne)
- 11 cech Ã— 3 MF = 3^11 = **177,147 reguÅ‚** (duÅ¼o!)
- 11 cech Ã— 4 MF = 4^11 = **4,194,304 reguÅ‚** (niemozliwe do interpretacji)

---

### ğŸ”¹1.12 Co to jest funkcja celu (loss function)?

**OdpowiedÅº:** Funkcja celu (straty) mierzy **jak bardzo predykcje modelu rÃ³Å¼niÄ… siÄ™ od prawdziwych wartoÅ›ci** - to "ocena" ktÃ³rÄ… model dostaje za swoje predykcje. Im mniejsza wartoÅ›Ä‡ loss, tym lepiej model przewiduje. Podczas uczenia model stara siÄ™ zminimalizowaÄ‡ tÄ™ funkcjÄ™, modyfikujÄ…c swoje wagi - to jak uczeÅ„ poprawiajÄ…cy swoje odpowiedzi, Å¼eby dostaÄ‡ lepszÄ… ocenÄ™. Funkcja loss musi byÄ‡ rÃ³Å¼niczkowalna, Å¼eby moÅ¼na byÅ‚o obliczyÄ‡ gradient i wiedzieÄ‡ "w ktÃ³rÄ… stronÄ™" zmieniaÄ‡ wagi.

**Dlaczego rÃ³Å¼ne funkcje dla rÃ³Å¼nych zadaÅ„?**

- **Klasyfikacja** (0 lub 1): Binary Cross-Entropy karze "pewnoÅ›Ä‡ siebie" modelu gdy siÄ™ myli - jeÅ›li model jest 99% pewny Å¼e wino jest dobre, a ono jest zÅ‚e, dostaje bardzo duÅ¼Ä… karÄ™
- **Regresja** (wartoÅ›Ä‡ ciÄ…gÅ‚a): MSE karze proporcjonalnie do kwadratu bÅ‚Ä™du - im bardziej siÄ™ mylisz, tym wiÄ™ksza kara

**W projekcie uÅ¼ywamy:**

| Zadanie             | Loss Function        | Co robi                              | WzÃ³r                                                      |
| ------------------- | -------------------- | ------------------------------------ | --------------------------------------------------------- |
| Klasyfikacja (wine) | Binary Cross-Entropy | Karze pewnoÅ›Ä‡ w bÅ‚Ä™dnych predykcjach | $-\frac{1}{n}\sum[y\log(\hat{y}) + (1-y)\log(1-\hat{y})]$ |
| Regresja (concrete) | MSE                  | Karze kwadrat odchylenia od celu     | $\frac{1}{n}\sum(y - \hat{y})^2$                          |

**Gdzie w kodzie:** [train_anfis.py](train_anfis.py#L109-L121)

```python
# Klasyfikacja (wine)
loss="binary_crossentropy"

# Regresja (concrete)
loss="mean_squared_error"
```

---

### ğŸ”¹ 1.13 Dlaczego optymalizator jest niezbÄ™dny?

**OdpowiedÅº:** Optymalizator jest niezbÄ™dny, bo to on umoÅ¼liwia uczenie siÄ™ modelu â€“ bez niego wagi sieci nie zmieniaÅ‚yby siÄ™ i model nie poprawiaÅ‚by swoich predykcji. Optymalizator decyduje, jak i o ile zmieniÄ‡ parametry na podstawie gradientu, by minimalizowaÄ‡ bÅ‚Ä…d (funkcjÄ™ celu). Bez optymalizatora model byÅ‚by statyczny i nie nauczyÅ‚by siÄ™ niczego z danych â€“ to on â€napÄ™dzaâ€ caÅ‚y proces uczenia. RÃ³Å¼ne optymalizatory (SGD, Adam, Nadam) rÃ³Å¼niÄ… siÄ™ strategiÄ… aktualizacji wag, ale kaÅ¼dy z nich jest absolutnie konieczny, by model mÃ³gÅ‚ siÄ™ uczyÄ‡.

**Podstawowa idea - Gradient Descent:**
$$w_{t+1} = w_t - \eta \cdot \nabla L(w_t)$$

- $w_t$ = aktualne wagi
- $\eta$ = learning rate (jak duÅ¼y krok)
- $\nabla L$ = gradient funkcji straty (kierunek "w dÃ³Å‚")

**Optymalizatory w projekcie:**

| Optymalizator       | Co robi                                     | Kiedy uÅ¼ywaÄ‡                                |
| ------------------- | ------------------------------------------- | ------------------------------------------- |
| **Nadam** (w ANFIS) | Adam + Nesterov momentum - "patrzy w przÃ³d" | Dobry domyÅ›lny wybÃ³r                        |
| **Adam** (w NN)     | Adaptive learning rate + momentum           | Najpopularniejszy, dziaÅ‚a dobrze            |
| **SGD**             | Podstawowy gradient descent                 | Wymaga tuningu, ale moÅ¼e daÄ‡ lepsze minimum |

**Gdzie w kodzie:** [train_anfis.py](train_anfis.py#L110)

```python
optimizer=tf.keras.optimizers.Nadam(learning_rate=0.001)
```

---

### ğŸ”¹ 1.14 Dlaczego stosuje siÄ™ mini-batch?

**OdpowiedÅº:** Mini-batch to sposÃ³b przetwarzania danych podczas uczenia, gdzie zamiast uÅ¼ywaÄ‡ wszystkich prÃ³bek naraz (zbyt wolne) lub pojedynczych prÃ³bek (zbyt chaotyczne), uÅ¼ywamy maÅ‚ych porcji np. 32 prÃ³bek. To jak jedzenie - nie jesz caÅ‚ego obiadu na raz (zakrztusisz siÄ™), ani kÄ™s po kÄ™sie przez 3 godziny (za wolno), tylko normalne porcje. Mini-batch daje stabilniejszy gradient niÅ¼ pojedyncze prÃ³bki, ale jest szybszy niÅ¼ peÅ‚ny batch i mieÅ›ci siÄ™ w pamiÄ™ci GPU.

**PorÃ³wnanie podejÅ›Ä‡:**

| Tryb           | Batch size    | Zalety                      | Wady                                 |
| -------------- | ------------- | --------------------------- | ------------------------------------ |
| **SGD online** | 1 prÃ³bka      | Bardzo szybka aktualizacja  | Chaotyczny gradient, wolna zbieÅ¼noÅ›Ä‡ |
| **Batch GD**   | wszystkie (n) | Stabilny, dokÅ‚adny gradient | Bardzo wolne, wymaga duÅ¼o RAM        |
| **Mini-batch** | 32-256        | ZÅ‚oty Å›rodek                | -                                    |

**Konkretne zalety mini-batch:**

1. **Regularyzacja** - szum w gradiencie (bo liczymy z prÃ³bki, nie caÅ‚oÅ›ci) pomaga uciec z lokalnych minimÃ³w i zapobiega przeuczeniu
2. **EfektywnoÅ›Ä‡ GPU** - karty graficzne sÄ… zoptymalizowane pod operacje macierzowe na wielu danych naraz (32 prÃ³bki Ã— 11 cech = macierz 32Ã—11)
3. **PamiÄ™Ä‡** - nie trzeba trzymaÄ‡ caÅ‚ego zbioru (6497 prÃ³bek) w pamiÄ™ci GPU, wystarczy 32

**Gdzie w kodzie:** [train_anfis.py](train_anfis.py#L141-L145)

```python
history = anfis_model.model.fit(
    X_train, y_train,
    ...
    batch_size=batch_size,  # domyÅ›lnie 32
    ...
)
```

---

## 3. Zadania do wykonania

### âœ… 2.1 Zmiana liczby funkcji przynaleÅ¼noÅ›ci

**Lokalizacja:** [train_anfis.py](train_anfis.py#L579-L585) lub wywoÅ‚anie z CLI

```bash
# Z linii komend:
python train_anfis.py --datasets all --memb 2 3 4 --epochs 20

# W kodzie - bezpoÅ›rednie wywoÅ‚anie:
train_anfis_model(n_memb=4, epochs=20, dataset="all")
```

**Jak to wpÅ‚ywa na model:**

- WiÄ™cej MF = wiÄ™cej reguÅ‚ = wiÄ™ksza ekspresywnoÅ›Ä‡
- n_memb=2 â†’ 2^11 = 2048 reguÅ‚
- n_memb=3 â†’ 3^11 = 177,147 reguÅ‚

---

### âœ… 2.2 Zmiana liczby iteracji (epok)

**Lokalizacja:** [train_anfis.py](train_anfis.py#L583)

```bash
python train_anfis.py --epochs 50  # zamiast 20
```

**Lub w kodzie:**

```python
train_anfis_model(n_memb=2, epochs=50, dataset="all")
```

---

### âœ… 2.3 Uczenie na wybranych atrybutach

**Jak zmodyfikowaÄ‡:** ZmieÅ„ listÄ™ `feature_columns` w [data_preprocessing.py](data_preprocessing.py#L40-42)

```python
# Oryginalne - wszystkie 11 cech:
feature_columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',
                  'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',
                  'pH', 'sulphates', 'alcohol']

# Zmodyfikowane - tylko 5 najwaÅ¼niejszych (przykÅ‚ad):
feature_columns = ['alcohol', 'volatile acidity', 'sulphates', 'citric acid', 'density']
```

**Po zmianie:**

1. Uruchom `python data_preprocessing.py`
2. Uruchom `python train_anfis.py`

---

### âœ… 2.4 Wypisanie reguÅ‚ ANFIS

**Lokalizacja:** [train_anfis.py](train_anfis.py#L429-L500) - funkcja `extract_and_save_rules()`

**Wyniki:** `results/anfis_*_rules.json`

**Format reguÅ‚y:**

```json
{
  "rule_index": 0,
  "membership_indices": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
  "consequent": {
    "weights": [0.123, -0.456, ...],  // wagi dla kaÅ¼dej cechy
    "bias": 0.789
  }
}
```

**Interpretacja:** ReguÅ‚a 0 mÃ³wi:

> JEÅšLI cecha_0 jest LOW (MF 0) ORAZ cecha_1 jest LOW ORAZ ... ORAZ cecha_10 jest LOW
> TO y = 0.789 + 0.123Â·xâ‚€ - 0.456Â·xâ‚ + ...

---

### âœ… 2.5WyÅ›wietlenie funkcji przynaleÅ¼noÅ›ci PRZED i PO uczeniu

**Lokalizacja:** [train_anfis.py](train_anfis.py#L140-L160) - automatycznie zapisuje MF przed i po treningu

**Co siÄ™ dzieje automatycznie:**
Podczas treningu ANFIS automatycznie zapisywane sÄ… parametry funkcji przynaleÅ¼noÅ›ci:

- **PRZED treningiem:** `results/mf_centers_before_{dataset}_{n_memb}memb.npy` i `results/mf_sigmas_before_{dataset}_{n_memb}memb.npy`
- **PO treningu:** `results/mf_centers_after_{dataset}_{n_memb}memb.npy` i `results/mf_sigmas_after_{dataset}_{n_memb}memb.npy`

**Kod w train_anfis.py (automatycznie wykonywany):**

```python
# PRZED TRENINGIEM - zapisz poczÄ…tkowe MF
anfis_model.update_weights()
centers_before, sigmas_before = anfis_model.get_membership_functions()
np.save(f"results/mf_centers_before_{dataset}_{n_memb}memb.npy", centers_before)
np.save(f"results/mf_sigmas_before_{dataset}_{n_memb}memb.npy", sigmas_before)

# ... trening model.fit() ...

# PO TRENINGU - zapisz koÅ„cowe MF
anfis_model.update_weights()
centers_after, sigmas_after = anfis_model.get_membership_functions()
np.save(f"results/mf_centers_after_{dataset}_{n_memb}memb.npy", centers_after)
np.save(f"results/mf_sigmas_after_{dataset}_{n_memb}memb.npy", sigmas_after)
```

**Jak wyÅ›wietliÄ‡ porÃ³wnanie PRZED vs PO:**

```python
import numpy as np
import matplotlib.pyplot as plt

# Wczytaj parametry
dataset, n_memb = "all", 2
centers_before = np.load(f"results/mf_centers_before_{dataset}_{n_memb}memb.npy")
sigmas_before = np.load(f"results/mf_sigmas_before_{dataset}_{n_memb}memb.npy")
centers_after = np.load(f"results/mf_centers_after_{dataset}_{n_memb}memb.npy")
sigmas_after = np.load(f"results/mf_sigmas_after_{dataset}_{n_memb}memb.npy")

# PorÃ³wnaj np. dla cechy 0 (fixed acidity)
feature_idx = 0
x = np.linspace(-3, 3, 200)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
for mf in range(n_memb):
    c, s = centers_before[mf, feature_idx], sigmas_before[mf, feature_idx]
    ax1.plot(x, np.exp(-0.5 * ((x - c) / s)**2), label=f'MF {mf}')
ax1.set_title("PRZED treningiem")
ax1.legend()

for mf in range(n_memb):
    c, s = centers_after[mf, feature_idx], sigmas_after[mf, feature_idx]
    ax2.plot(x, np.exp(-0.5 * ((x - c) / s)**2), label=f'MF {mf}')
ax2.set_title("PO treningu")
ax2.legend()

plt.savefig("results/mf_comparison_before_after.png")
plt.show()
```

**Co obserwowaÄ‡:**

- **Centra (c)** - czy przesunÄ™Å‚y siÄ™ do bardziej znaczÄ…cych wartoÅ›ci cech
- **SzerokoÅ›ci (Ïƒ)** - czy zwÄ™ziÅ‚y siÄ™ (wiÄ™ksza precyzja) lub rozszerzyÅ‚y (wiÄ™ksza generalizacja)
- DuÅ¼e zmiany = model duÅ¼o siÄ™ nauczyÅ‚ na tej cesze
- MaÅ‚e zmiany = cecha mniej istotna lub juÅ¼ byÅ‚a dobrze zainicjalizowana

**Wykresy PO treningu:** `results/membership_functions_*.png` (generowane przez `visualize_membership_functions.py`)

---

### âœ… 2.6 Zmiana optymalizatora / learning rate

**Lokalizacja:** [train_anfis.py](train_anfis.py#L109-L121)

```python
# OryginaÅ‚:
optimizer=tf.keras.optimizers.Nadam(learning_rate=0.001)

# Zmiana na Adam:
optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005)

# Zmiana na SGD z momentum:
optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)

# Zmiana na RMSprop:
optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001)
```

---

### âœ… 2.7 OmÃ³wienie wykresu historii funkcji celu

**Lokalizacja wykresÃ³w:** `results/anfis_*_training.png`

**Co pokazujÄ… wykresy:**

1. **Lewy wykres (Accuracy/MAE):**

   - Niebieska linia = Train
   - PomaraÅ„czowa linia = Validation
   - Czerwony punkt = najlepsza epoka

2. **Prawy wykres (Loss):**
   - Zielona linia = Train Loss
   - Czerwona linia = Validation Loss

**Jak interpretowaÄ‡:**

| Obserwacja                    | Diagnoza                                    |
| ----------------------------- | ------------------------------------------- |
| Train i Val malejÄ… razem      | âœ… Dobry trening                            |
| Train maleje, Val stoi/roÅ›nie | âš ï¸ Overfitting                              |
| Obie krzywe stojÄ… (stagnacja) | âš ï¸ Learning rate za maÅ‚y lub zÅ‚e minimum    |
| Oscylacje                     | âš ï¸ Learning rate za duÅ¼y                    |
| Szybki spadek â†’ plateau       | âœ… Normalne (szybkie uczenie â†’ fine-tuning) |

**Gdzie w kodzie:** [train_anfis.py](train_anfis.py#L200-L282) - `plot_training_history()`

---

## ğŸ¯ Szybka Å›ciÄ…gawka na obronÄ™

### NajwaÅ¼niejsze definicje

| PojÄ™cie              | Definicja jednozdaniowa                                        |
| -------------------- | -------------------------------------------------------------- |
| **ANFIS**            | Hybrydowy system Å‚Ä…czÄ…cy logikÄ™ rozmytÄ… z sieciami neuronowymi |
| **TSK**              | Model rozmyty z liniowymi konsekwentami (y = ax + b)           |
| **MF**               | Funkcja okreÅ›lajÄ…ca stopieÅ„ przynaleÅ¼noÅ›ci do zbioru rozmytego |
| **Cross-validation** | K-krotny podziaÅ‚ danych do stabilnej oceny modelu              |
| **Loss function**    | Funkcja mierzÄ…ca bÅ‚Ä…d predykcji (minimalizujemy jÄ…)            |
| **Optimizer**        | Algorytm aktualizujÄ…cy wagi w kierunku mniejszego bÅ‚Ä™du        |
| **Mini-batch**       | PodziaÅ‚ danych na porcje dla efektywniejszego treningu         |

## Co to jest gradient? (po ludzku)

Gradient to po prostu "kierunek najszybszego spadku" â€“ pokazuje, w ktÃ³rÄ… stronÄ™ trzeba zmieniÄ‡ parametry (np. wagi w sieci), Å¼eby najszybciej zmniejszyÄ‡ bÅ‚Ä…d. WyobraÅº sobie, Å¼e stoisz na gÃ³rce i chcesz zejÅ›Ä‡ na sam dÃ³Å‚: gradient to strzaÅ‚ka pokazujÄ…ca, gdzie jest najbardziej stromo w dÃ³Å‚. W uczeniu maszynowym algorytm korzysta z gradientu, by krok po kroku poprawiaÄ‡ model i zbliÅ¼aÄ‡ siÄ™ do najlepszego rozwiÄ…zania.

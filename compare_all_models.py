"""
Generuje wykresy porÃ³wnawcze modeli dla OBU problemÃ³w:
- Wine Quality (dataset 'all')
- Concrete Strength

Zapisuje je jako:
  - results/model_comparison_bar_wine.png
  - results/overfitting_analysis_wine.png
  - results/model_comparison_bar_concrete.png
  - results/overfitting_analysis_concrete.png

Uruchamianie:
    python3 compare_all_models.py
"""

import json  # Biblioteka do obsÅ‚ugi plikÃ³w JSON
import os  # Biblioteka do operacji na systemie plikÃ³w
import matplotlib  # Biblioteka do tworzenia wykresÃ³w
matplotlib.use("Agg")  # Ustawia backend matplotlib bez GUI (do zapisu plikÃ³w)
import matplotlib.pyplot as plt  # ModuÅ‚ do tworzenia wykresÃ³w
import numpy as np  # Biblioteka do operacji na tablicach numerycznych
import seaborn as sns  # Biblioteka do zaawansowanych wizualizacji

# ---------------------------------------------------------------------
# FUNKCJE POMOCNICZE
# ---------------------------------------------------------------------
def load_wine_results():
    """
    Wczytuje wyniki wszystkich modeli dla Wine Quality (dataset 'all').
    
    ObsÅ‚uguje:
    - 2 warianty ANFIS (2 i 3 funkcje przynaleÅ¼noÅ›ci)
    - 3 modele klasyczne (NN, SVM, Random Forest)
    
    Returns:
        Dict[nazwa_modelu, wyniki_json]
    """
    paths = {  # SÅ‚ownik mapujÄ…cy nazwy modeli na Å›cieÅ¼ki do plikÃ³w JSON
        "ANFIS (2 MF)": "results/anfis_all_2memb_results.json",  # ÅšcieÅ¼ka do wynikÃ³w ANFIS z 2 funkcjami przynaleÅ¼noÅ›ci
        "ANFIS (3 MF)": "results/anfis_all_3memb_results.json",  # ÅšcieÅ¼ka do wynikÃ³w ANFIS z 3 funkcjami przynaleÅ¼noÅ›ci
        "Neural Network": "results/nn_wine_results.json",  # ÅšcieÅ¼ka do wynikÃ³w sieci neuronowej
        "SVM": "results/svm_wine_results.json",  # ÅšcieÅ¼ka do wynikÃ³w Support Vector Machine
        "Random Forest": "results/rf_wine_results.json",  # ÅšcieÅ¼ka do wynikÃ³w Random Forest
    }
    results = {}  # Inicjalizuje pusty sÅ‚ownik na wyniki
    for name, path in paths.items():  # Iteruje przez wszystkie Å›cieÅ¼ki
        if os.path.exists(path):  # Sprawdza czy plik istnieje
            try:  # PrÃ³buje wczytaÄ‡ plik
                with open(path, "r", encoding="utf-8") as f:  # Otwiera plik JSON
                    data = json.load(f)  # Wczytuje dane JSON
                    if name in ["Neural Network", "SVM", "Random Forest"]:  # Sprawdza czy to model klasyczny
                        if "test_accuracy" in data:  # Sprawdza czy plik zawiera accuracy (dla wine)
                            results[name] = data  # Dodaje wyniki do sÅ‚ownika
                        else:  # JeÅ›li brak test_accuracy
                            print(f"Plik {path} nie zawiera 'test_accuracy' â€” pomijam dla Wine.")  # Informuje o braku metryki
                    else:  # Dla modeli ANFIS
                        results[name] = data  # Dodaje wyniki do sÅ‚ownika bez dodatkowej walidacji
            except Exception as e:  # Åapie bÅ‚Ä™dy wczytywania
                print(f"BÅ‚Ä…d wczytywania {path}: {e}")  # Wypisuje komunikat o bÅ‚Ä™dzie
        else:  # JeÅ›li plik nie istnieje
            print(f"Brak pliku: {path}")  # Informuje o braku pliku
    return results  # Zwraca sÅ‚ownik z wynikami


def load_concrete_results():
    """
    Wczytuje wyniki wszystkich modeli dla Concrete Strength.
    
    ObsÅ‚uguje:
    - 2 warianty ANFIS (2 i 3 funkcje przynaleÅ¼noÅ›ci)
    - 3 modele klasyczne (NN, SVM, Random Forest)
    
    Returns:
        Dict[nazwa_modelu, wyniki_json]
    """
    paths = {  # SÅ‚ownik mapujÄ…cy nazwy modeli na Å›cieÅ¼ki do plikÃ³w JSON dla betonu
        "ANFIS (2 MF)": "results/anfis_concrete_2memb_results.json",  # ANFIS z 2 funkcjami dla betonu
        "ANFIS (3 MF)": "results/anfis_concrete_3memb_results.json",  # ANFIS z 3 funkcjami dla betonu
        "Neural Network": "results/nn_concrete_results.json",  # SieÄ‡ neuronowa dla betonu
        "SVM": "results/svm_concrete_results.json",  # SVM dla betonu
        "Random Forest": "results/rf_concrete_results.json",  # Random Forest dla betonu
    }
    results = {}  # Inicjalizuje pusty sÅ‚ownik na wyniki
    for name, path in paths.items():  # Iteruje przez wszystkie Å›cieÅ¼ki
        if os.path.exists(path):  # Sprawdza czy plik istnieje
            try:  # PrÃ³buje wczytaÄ‡ plik
                with open(path, "r", encoding="utf-8") as f:  # Otwiera plik JSON
                    data = json.load(f)  # Wczytuje dane JSON
                    if name in ["Neural Network", "SVM", "Random Forest"]:  # Sprawdza czy to model klasyczny
                        if "test_mae" in data:  # Sprawdza czy plik zawiera MAE (dla regresji betonu)
                            results[name] = data  # Dodaje wyniki do sÅ‚ownika
                        else:  # JeÅ›li brak test_mae
                            print(f"Plik {path} nie zawiera 'test_mae' â€” pomijam dla Concrete.")  # Informuje o braku metryki
                    else:  # Dla modeli ANFIS
                        results[name] = data  # Dodaje wyniki bez dodatkowej walidacji
            except Exception as e:  # Åapie bÅ‚Ä™dy wczytywania
                print(f"BÅ‚Ä…d wczytywania {path}: {e}")  # Wypisuje komunikat o bÅ‚Ä™dzie
        else:  # JeÅ›li plik nie istnieje
            print(f"Brak pliku: {path}")  # Informuje o braku pliku
    return results  # Zwraca sÅ‚ownik z wynikami


def plot_comparison_bar_chart(results, is_regression, output_path, title_suffix):  # Funkcja generujÄ…ca wykres sÅ‚upkowy porÃ³wnujÄ…cy modele
    if not results:  # Sprawdza czy sÄ… wyniki do wyÅ›wietlenia
        print(f"Pomijam generowanie {output_path} â€” brak wynikÃ³w.")  # Informuje o braku danych
        return  # KoÅ„czy wykonanie funkcji

    models = list(results.keys())  # Pobiera listÄ™ nazw modeli
    train_vals, test_vals = [], []  # Inicjalizuje listy na wartoÅ›ci treningowe i testowe
    for m in models:  # Iteruje przez wszystkie modele
        res = results[m]  # Pobiera wyniki dla bieÅ¼Ä…cego modelu
        if is_regression:  # Sprawdza czy to zadanie regresji
            train_vals.append(res.get("train_mae", np.nan))  # Dodaje train MAE (lub NaN jeÅ›li brak)
            test_vals.append(res.get("test_mae", np.nan))  # Dodaje test MAE (lub NaN jeÅ›li brak)
        else:  # Dla zadania klasyfikacji
            train_vals.append(res.get("train_accuracy", np.nan) * 100)  # Konwertuje accuracy na procenty (0.95 -> 95%)
            test_vals.append(res.get("test_accuracy", np.nan) * 100)  # Konwertuje test accuracy na procenty

    x = np.arange(len(models))  # Tworzy tablicÄ™ pozycji dla modeli (0, 1, 2, ...)
    width = 0.35  # SzerokoÅ›Ä‡ sÅ‚upkÃ³w (35% odstÄ™pu miÄ™dzy pozycjami)
    fig, ax = plt.subplots(figsize=(12, 7))  # Tworzy figurÄ™ wykresu o wymiarach 12x7 cali

    label_train = "Train MAE" if is_regression else "Train Accuracy (%)"  # Ustawia etykietÄ™ dla danych treningowych
    label_test = "Test MAE" if is_regression else "Test Accuracy (%)"  # Ustawia etykietÄ™ dla danych testowych

    bars1 = ax.bar(x - width / 2, train_vals, width, label=label_train, color="steelblue", alpha=0.8, edgecolor="black")  # Rysuje sÅ‚upki treningowe (przesuniÄ™te w lewo)
    bars2 = ax.bar(x + width / 2, test_vals, width, label=label_test, color="coral", alpha=0.8, edgecolor="black")  # Rysuje sÅ‚upki testowe (przesuniÄ™te w prawo)

    ax.set_xlabel("Model", fontsize=14, fontweight="bold")  # Ustawia etykietÄ™ osi X
    ylabel = "MAE (niÅ¼ej = lepiej)" if is_regression else "DokÅ‚adnoÅ›Ä‡ (%)"  # OkreÅ›la etykietÄ™ osi Y w zaleÅ¼noÅ›ci od typu zadania
    ax.set_ylabel(ylabel, fontsize=14, fontweight="bold")  # Ustawia etykietÄ™ osi Y
    ax.set_title(f"PorÃ³wnanie modeli â€” {title_suffix}", fontsize=16, fontweight="bold", pad=20)  # Ustawia tytuÅ‚ wykresu z paddingiem 20
    ax.set_xticks(x)  # Ustawia pozycje znacznikÃ³w na osi X
    ax.set_xticklabels(models, rotation=15, ha="right")  # Ustawia nazwy modeli obrÃ³cone o 15Â° i wyrÃ³wnane do prawej
    ax.legend(fontsize=12)  # Dodaje legendÄ™ z rozmiarem czcionki 12
    ax.grid(axis="y", alpha=0.3, linestyle="--")  # Dodaje poziomÄ… siatkÄ™ z przerywanÄ… liniÄ…

    for bars in [bars1, bars2]:  # Iteruje przez obydwa zestawy sÅ‚upkÃ³w
        for bar in bars:  # Iteruje przez kaÅ¼dy sÅ‚upek
            height = bar.get_height()  # Pobiera wysokoÅ›Ä‡ sÅ‚upka (wartoÅ›Ä‡ metryki)
            if np.isnan(height):  # Sprawdza czy wartoÅ›Ä‡ jest NaN
                continue  # Pomija NaN wartoÅ›ci
            text = f"{height:.2f}" if is_regression else f"{height:.1f}%"  # Formatuje tekst (2 miejsca dla MAE, 1 dla %)
            offset = 0.02 if is_regression else 0.5  # Ustawia przesuniÄ™cie tekstu nad sÅ‚upkiem
            ax.text(bar.get_x() + bar.get_width() / 2., height + offset,  # Umieszcza tekst nad Å›rodkiem sÅ‚upka
                    text, ha="center", va="bottom", fontsize=9)  # WyrÃ³wnanie centralne, od doÅ‚u, rozmiar 9

    plt.tight_layout()  # Automatycznie dopasowuje ukÅ‚ad
    plt.savefig(output_path, dpi=300, bbox_inches="tight")  # Zapisuje wykres w wysokiej rozdzielczoÅ›ci
    plt.close()  # Zamyka wykres aby zwolniÄ‡ pamiÄ™Ä‡
    print(f"âœ“ Zapisano: {output_path}")  # Informuje o zapisie pliku


def plot_overfitting_analysis(results, is_regression, output_path):  # Funkcja analizujÄ…ca overfitting (rÃ³Å¼nice train vs test)
    if not results:  # Sprawdza czy sÄ… wyniki
        print(f"âš ï¸ Pomijam generowanie {output_path} â€” brak wynikÃ³w.")  # Informuje o braku danych
        return  # KoÅ„czy wykonanie

    models = list(results.keys())  # Pobiera listÄ™ nazw modeli
    train_vals, test_vals = [], []  # Inicjalizuje listy na wartoÅ›ci
    for m in models:  # Iteruje przez modele
        res = results[m]  # Pobiera wyniki modelu
        if is_regression:  # Dla regresji
            train_vals.append(res.get("train_mae", np.nan))  # Pobiera train MAE
            test_vals.append(res.get("test_mae", np.nan))  # Pobiera test MAE
        else:  # Dla klasyfikacji
            train_vals.append(res.get("train_accuracy", np.nan) * 100)  # Konwertuje accuracy na procenty
            test_vals.append(res.get("test_accuracy", np.nan) * 100)  # Konwertuje test accuracy na procenty

    overfit_gap = []  # Lista na rÃ³Å¼nice (gap) wskazujÄ…ce overfitting
    for t, v in zip(train_vals, test_vals):  # Iteruje przez pary wartoÅ›ci
        if np.isnan(t) or np.isnan(v):  # Sprawdza czy ktÃ³raÅ› wartoÅ›Ä‡ to NaN
            overfit_gap.append(np.nan)  # Dodaje NaN do listy
        else:  # JeÅ›li obydwie wartoÅ›ci sÄ… poprawne
            gap = (t - v) if not is_regression else (v - t)  # Oblicza rÃ³Å¼nicÄ™ (train-test dla klasyfikacji, test-train dla regresji)
            overfit_gap.append(gap)  # Dodaje rÃ³Å¼nicÄ™ do listy

    fig, ax = plt.subplots(figsize=(10, 6))  # Tworzy figurÄ™ wykresu poziomego
    colors = []  # Lista na kolory sÅ‚upkÃ³w (zaleÅ¼ne od wielkoÅ›ci gap)
    for gap in overfit_gap:  # Iteruje przez wszystkie rÃ³Å¼nice
        if np.isnan(gap):  # JeÅ›li brak danych
            colors.append("gray")  # Szary kolor dla NaN
        elif abs(gap) < (1 if not is_regression else 2):  # JeÅ›li rÃ³Å¼nica bardzo maÅ‚a (<1% lub <2 MAE)
            colors.append("green")  # Zielony = dobry model (maÅ‚y overfitting)
        elif abs(gap) < (5 if not is_regression else 5):  # JeÅ›li rÃ³Å¼nica Å›rednia (<5% lub <5 MAE)
            colors.append("orange")  # PomaraÅ„czowy = umiarkowany overfitting
        else:  # JeÅ›li rÃ³Å¼nica duÅ¼a (â‰¥5% lub â‰¥5 MAE)
            colors.append("red")  # Czerwony = duÅ¼y overfitting

    bars = ax.barh(models, overfit_gap, color=colors, alpha=0.8, edgecolor="black")  # Rysuje poziome sÅ‚upki z kolorami
    label_x = "RÃ³Å¼nica (Train - Test) [%]" if not is_regression else "RÃ³Å¼nica (Test - Train) [MAE]"  # Etykieta osi X
    ax.set_xlabel(label_x, fontsize=13, fontweight="bold")  # Ustawia etykietÄ™ osi X
    ax.set_title("Analiza Overfittingu (mniejsza rÃ³Å¼nica = lepiej)", fontsize=15, fontweight="bold", pad=15)  # TytuÅ‚ wykresu
    ax.grid(axis="x", alpha=0.3, linestyle="--")  # Dodaje pionowÄ… siatkÄ™

    # Ustaw granice osi X, aby obejmowaÅ‚y wszystkie wartoÅ›ci
    min_val = min([x for x in overfit_gap if not np.isnan(x)] + [0])  # Znajduje minimalnÄ… wartoÅ›Ä‡ (wÅ‚Ä…cznie z 0)
    max_val = max([x for x in overfit_gap if not np.isnan(x)] + [0])  # Znajduje maksymalnÄ… wartoÅ›Ä‡ (wÅ‚Ä…cznie z 0)
    ax.set_xlim(left=min_val - 0.5, right=max_val + 0.5)  # Ustawia granice osi X z marginesem 0.5

    for i, (bar, val) in enumerate(zip(bars, overfit_gap)):  # Iteruje przez sÅ‚upki i wartoÅ›ci
        if np.isnan(val):  # Pomija NaN wartoÅ›ci
            continue  # Przechodzi do nastÄ™pnej iteracji
        text_x = bar.get_width() + 0.05  # Oblicza pozycjÄ™ X tekstu (za koÅ„cem sÅ‚upka)
        ax.text(text_x, i, f"{val:.2f}", va="center", ha='left', fontsize=10, fontweight="bold", color="black")  # Dodaje wartoÅ›Ä‡ jako tekst

    plt.tight_layout()  # Dopasowuje ukÅ‚ad
    plt.savefig(output_path, dpi=300, bbox_inches="tight")  # Zapisuje wykres
    plt.close()  # Zamyka wykres
    print(f"âœ“ Zapisano: {output_path}")  # Informuje o zapisie


# ---------------------------------------------------------------------
# GÅÃ“WNY BLOK â€” generuje wszystko automatycznie
# ---------------------------------------------------------------------
if __name__ == "__main__":  # Sprawdza czy skrypt uruchamiany bezpoÅ›rednio
    print("======================================")  # Separator wizualny
    print("STEP 5: Model Comparison")  # Wypisuje nazwÄ™ kroku
    print("======================================")  # Separator wizualny

    # --- Wine Quality (all) ---
    print("\nğŸ· ÅadujÄ™ wyniki dla Wine Quality (dataset 'all')...")  # Informuje o Å‚adowaniu wynikÃ³w wina
    wine_results = load_wine_results()  # Åaduje wyniki wszystkich modeli dla wine
    if wine_results:  # Sprawdza czy sÄ… wyniki
        plot_comparison_bar_chart(wine_results, is_regression=False,  # Generuje wykres sÅ‚upkowy (klasyfikacja)
                                  output_path="results/model_comparison_bar_wine.png",
                                  title_suffix="Wine Quality (all)")
        plot_overfitting_analysis(wine_results, is_regression=False,  # Generuje analizÄ™ overfitting
                                  output_path="results/overfitting_analysis_wine.png")
    else:  # JeÅ›li brak wynikÃ³w
        print("Pomijam Wine â€” brak wynikÃ³w.")  # Informuje o pominiÄ™ciu

    # --- Concrete Strength ---
    print("\nğŸ—ï¸ ÅadujÄ™ wyniki dla Concrete Strength...")  # Informuje o Å‚adowaniu wynikÃ³w betonu
    concrete_results = load_concrete_results()  # Åaduje wyniki wszystkich modeli dla concrete
    if concrete_results:  # Sprawdza czy sÄ… wyniki
        plot_comparison_bar_chart(concrete_results, is_regression=True,  # Generuje wykres sÅ‚upkowy (regresja)
                                  output_path="results/model_comparison_bar_concrete.png",
                                  title_suffix="Concrete Strength")
        plot_overfitting_analysis(concrete_results, is_regression=True,  # Generuje analizÄ™ overfitting
                                  output_path="results/overfitting_analysis_concrete.png")
    else:  # JeÅ›li brak wynikÃ³w
        print("Pomijam Concrete â€” brak wynikÃ³w.")  # Informuje o pominiÄ™ciu

    print("\nPorÃ³wnanie modeli zakoÅ„czone!")  # Informuje o zakoÅ„czeniu
# ğŸ¤– ANFIS vs Classical Machine Learning Models

Comprehensive comparison of **ANFIS (Adaptive Neuro-Fuzzy Inference System)** with classical machine learning algorithms on two real-world datasets.

---

## ğŸ“Š Datasets

### 1. **Wine Quality Classification** ğŸ·

- **Source**: [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/wine+quality)
- **Samples**: 6,497 (1,599 red + 4,898 white)
- **Features**: 11 physicochemical properties
  - Fixed acidity, volatile acidity, citric acid
  - Residual sugar, chlorides
  - Free/total sulfur dioxide
  - Density, pH, sulphates, alcohol
- **Task**: Binary classification (quality > 5 vs â‰¤ 5)
- **Variants**:
  - `all`: Combined red + white wines
  - `red`: Red wines only
  - `white`: White wines only

### 2. **Concrete Compressive Strength Prediction** ğŸ—ï¸

- **Source**: [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength)
- **Samples**: 1,030
- **Features**: 8 components
  - Cement, blast furnace slag, fly ash
  - Water, superplasticizer
  - Coarse/fine aggregate, age (days)
- **Task**: Regression (predict compressive strength in MPa)

---

## ğŸ§  Models Compared

| Model              | Type           | Configuration                       |
| ------------------ | -------------- | ----------------------------------- |
| **ANFIS**          | Neuro-Fuzzy    | 2 & 3 Gaussian membership functions |
| **Neural Network** | Deep Learning  | Multi-layer perceptron              |
| **SVM**            | Kernel Methods | RBF kernel                          |
| **Random Forest**  | Ensemble       | 300 trees                           |

---

## ğŸ—ï¸ ANFIS Architecture

**5-Layer Takagi-Sugeno-Kang System:**

```
Input â†’ Fuzzy Layer â†’ Rule Layer â†’ Norm Layer â†’ Defuzz Layer â†’ Output
```

1. **Fuzzy Layer**: Gaussian membership functions

   - Î¼(x) = exp(-(x-c)Â²/(2ÏƒÂ²))
   - Each feature: 2 or 3 MFs

2. **Rule Layer**: Fuzzy rule generation

   - Rules = n_memb ^ n_features
   - Example: 11 features Ã— 2 MF = 2,048 rules

3. **Norm Layer**: Rule weight normalization

4. **Defuzz Layer**: TSK-type defuzzification

   - f_i = wâ‚€ + wâ‚xâ‚ + ... + wâ‚™xâ‚™

5. **Summation Layer**: Weighted output aggregation

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+ (tested on 3.12)
- pip package manager
- 4GB RAM minimum
- ~1GB disk space

### One-Command Setup

**Linux/macOS:**

```bash
chmod +x setup.sh
./setup.sh
```

**Windows:**

```bash
setup.bat
```

This single command will:

1. Create virtual environment
2. Install all dependencies
3. Preprocess both datasets
4. Train ANFIS models (all variants)
5. Perform 5-fold cross-validation
6. Visualize membership functions
7. Generate data exploration plots
8. Train comparison models (NN, SVM, RF)
9. Create comparison charts
10. Launch Streamlit GUI at `http://localhost:8501`

**â±ï¸ Estimated time**: 15-30 minutes (depending on your CPU)

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ setup.sh / setup.bat          # Automated setup script
â”œâ”€â”€ requirements.txt               # Python dependencies
â”‚
â”œâ”€â”€ data/                          # Raw datasets
â”‚   â”œâ”€â”€ wine-quality/
â”‚   â”‚   â”œâ”€â”€ winequality-red.csv
â”‚   â”‚   â””â”€â”€ winequality-white.csv
â”‚   â””â”€â”€ concrete-strength/
â”‚       â””â”€â”€ Concrete_Data.csv
â”‚
â”œâ”€â”€ anfis.py                       # ANFIS core implementation
â”œâ”€â”€ data_preprocessing.py          # Data loading & normalization
â”œâ”€â”€ train_anfis.py                 # ANFIS training pipeline
â”œâ”€â”€ train_comparison_models.py     # Train NN, SVM, RF
â”œâ”€â”€ compare_all_models.py          # Generate comparison plots
â”œâ”€â”€ visualize_membership_functions.py
â”œâ”€â”€ data_exploration.py            # EDA visualizations
â”‚
â”œâ”€â”€ app.py                         # Streamlit web interface
â”‚
â”œâ”€â”€ models/                        # Trained model weights
â””â”€â”€ results/                       # Generated plots & metrics
```

---

## ğŸ“Š Results & Visualizations

The automated pipeline generates:

### ANFIS Results (per dataset Ã— MF configuration):

- Training curves (accuracy/MAE + loss)
- Prediction scatter plots
- Membership function plots
- Cross-validation metrics (5-fold)
- Fuzzy rule extraction (top-K rules)

### Data Exploration:

- Class/target distribution plots
- Feature correlation heatmaps
- Feature distribution histograms
- Pairplots for key features

### Model Comparison:

- Accuracy/MAE bar charts
- Overfitting analysis (train-test gap)
- Performance ranking table

---

## ğŸ¯ Key Features

âœ… **Fully Automated**: Single command setup  
âœ… **Two Problem Types**: Classification + Regression  
âœ… **Multiple Datasets**: 4 configurations (concrete, all, red, white)  
âœ… **Cross-Validation**: 5-fold stratified/standard  
âœ… **Interactive GUI**: Streamlit web dashboard  
âœ… **Rule Extraction**: Interpretable fuzzy rules  
âœ… **Comprehensive Comparison**: 4 ML algorithms  
âœ… **Publication-Ready Plots**: 300 DPI PNG exports

---

## ğŸ”¬ Technical Details

### Preprocessing

- **Wine**: StandardScaler per dataset variant, 80/20 split
- **Concrete**: StandardScaler, 80/20 split
- **ANFIS Input Range**: Normalized to [-3, 3]

### Training Configuration

- **Optimizer**: Nadam (lr=0.001)
- **Epochs**: 20 (early stopping patience=10)
- **Batch Size**: 32
- **Loss Functions**:
  - Wine: Binary crossentropy
  - Concrete: Mean Squared Error

### Cross-Validation

- **Wine**: 5-fold Stratified (preserves class balance)
- **Concrete**: 5-fold Standard (regression)

---

## ğŸ“– Documentation

- **[MANUAL_INSTRUCTION.md](MANUAL_INSTRUCTION.md)**: Detailed step-by-step installation guide
- **Code Documentation**: All functions have Polish docstrings

---

## ğŸ‘¥ Authors

- **Dawid Olko** - Project Lead
- **Piotr SmoÅ‚a** - ML Implementation
- **Jakub Opar** - Data Analysis
- **MichaÅ‚ Pilecki** - Visualization

---

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ“š References

1. **ANFIS**: J.-S. R. Jang, "ANFIS: adaptive-network-based fuzzy inference system," IEEE Transactions on Systems, Man, and Cybernetics, vol. 23, no. 3, pp. 665-685, 1993.
2. **Wine Quality Dataset**: P. Cortez et al., "Modeling wine preferences by data mining from physicochemical properties," Decision Support Systems, 2009.
3. **Concrete Dataset**: I-C. Yeh, "Modeling of strength of high-performance concrete using artificial neural networks," Cement and Concrete Research, 1998.

---

## ğŸ› Troubleshooting

**Issue**: Streamlit doesn't launch automatically  
**Solution**: Manually run `streamlit run app.py` after setup completes

**Issue**: TensorFlow installation fails  
**Solution**: Ensure Python 3.8-3.12. TensorFlow 2.17 not compatible with 3.13+

**Issue**: Out of memory during training  
**Solution**: Reduce batch size in `train_anfis.py` (line 95: `batch_size=16`)

---

## â­ Star This Repo!

If this project helped your research or learning, please consider giving it a star â­

**Questions?** Open an issue on GitHub!

1. **Fuzzy Layer**: Gaussian membership functionsâ”œâ”€â”€ results/ # Wykresy i wyniki (generowane)

   - Î¼(x) = exp(-(x-c)Â²/(2ÏƒÂ²))â”‚ â”œâ”€â”€ all_models_comparison.png

   - Each feature: 2 or 3 MFsâ”‚ â”œâ”€â”€ overfitting_analysis.png

â”‚ â”œâ”€â”€ anfis_2memb_training.png

2. **Rule Layer**: Fuzzy rule generationâ”‚ â”œâ”€â”€ anfis_3memb_training.png

   - Rules = n_memb ^ n_featuresâ”‚ â”œâ”€â”€ membership_functions_visualization.png

   - Example: 11 features Ã— 2 MF = 2,048 rulesâ”‚ â””â”€â”€ \*.json (wyniki liczbowe)

â”œâ”€â”€ anfis.py # âš™ï¸ Implementacja ANFIS

3. **Norm Layer**: Rule weight normalizationâ”œâ”€â”€ data_exploration.py # ğŸ“Š Eksploracja danych

â”œâ”€â”€ data_preprocessing.py # ğŸ”„ Przygotowanie danych

4. **Defuzz Layer**: TSK-type defuzzificationâ”œâ”€â”€ train_anfis.py # ğŸ§  Trening modeli ANFIS

   - f_i = wâ‚€ + wâ‚xâ‚ + ... + wâ‚™xâ‚™â”œâ”€â”€ train_comparison_models.py # ğŸ¤– Trening modeli porÃ³wnawczych

â”œâ”€â”€ compare_all_models.py # ğŸ“ˆ PorÃ³wnanie wynikÃ³w

5. **Summation Layer**: Weighted output aggregationâ”œâ”€â”€ visualize_membership_functions.py # ğŸ“‰ Wizualizacja funkcji przynaleÅ¼noÅ›ci

â”œâ”€â”€ utils.py # ğŸ› ï¸ Funkcje pomocnicze (NOWE v1.1.0)

---â”œâ”€â”€ scaller.py # ğŸ“ Åadowanie scalerÃ³w (NOWE v1.1.0)

â”œâ”€â”€ app.py # ğŸ· Interfejs Streamlit

## ğŸš€ Quick Startâ”œâ”€â”€ main.py # ğŸš€ GÅ‚Ã³wny pipeline

â”œâ”€â”€ requirements.txt # ğŸ“¦ ZaleÅ¼noÅ›ci

### Prerequisitesâ””â”€â”€ .gitignore # ğŸš« Pliki ignorowane przez Git

- Python 3.8+ (tested on 3.12)```

- pip package manager

- 4GB RAM minimum**Legenda:**

- ~1GB disk space

- ğŸ“ Foldery generowane automatycznie podczas uruchomienia

### One-Command Setup- ğŸ†• **NOWE w v1.1.0:** ModuÅ‚y `utils.py` i `scaller.py` do separacji logiki biznesowej

**Linux/macOS:**---

````bash

chmod +x setup.sh## ğŸ”§ Wymagania

./setup.sh

```### Wymagane biblioteki:



**Windows:**```

```bashtensorflow==2.17.0

setup.batnumpy==1.26.4

```pandas==2.2.3

scikit-learn==1.5.2

This single command will:matplotlib==3.9.2

1. Create virtual environmentseaborn==0.12.2

2. Install all dependenciesstreamlit==1.39.0

3. Preprocess both datasetsh5py==3.12.1

4. Train ANFIS models (all variants)pillow==11.0.0

5. Perform 5-fold cross-validation```

6. Visualize membership functions

7. Generate data exploration plots### Instalacja:

8. Train comparison models (NN, SVM, RF)

9. Create comparison charts```bash

10. Launch Streamlit GUI at `http://localhost:8501`pip install -r requirements.txt

````

**â±ï¸ Estimated time**: 15-30 minutes (depending on your CPU)

### Automatyczne skrypty setup:

---

```bash

## ğŸ“ Project Structure# Windows

setup.bat

```

â”œâ”€â”€ setup.sh / setup.bat # Automated setup script# Linux/macOS

â”œâ”€â”€ requirements.txt # Python dependencieschmod +x setup.sh

â”‚./setup.sh

â”œâ”€â”€ data/ # Raw datasets```

â”‚ â”œâ”€â”€ wine-quality/

â”‚ â”‚ â”œâ”€â”€ winequality-red.csv---

â”‚ â”‚ â””â”€â”€ winequality-white.csv

â”‚ â””â”€â”€ concrete-strength/## ğŸ†• Zmiany w wersji 1.1.0

â”‚ â””â”€â”€ Concrete_Data.csv

â”‚### âœ… Optymalizacje wykonane:

â”œâ”€â”€ anfis.py # ANFIS core implementation

â”œâ”€â”€ data_preprocessing.py # Data loading & normalization1. **ğŸ–¼ï¸ Naprawiono blokowanie przez matplotlib**

â”œâ”€â”€ train_anfis.py # ANFIS training pipeline

â”œâ”€â”€ train_comparison_models.py # Train NN, SVM, RF - Dodano `matplotlib.use('Agg')` do wszystkich skryptÃ³w

â”œâ”€â”€ compare_all_models.py # Generate comparison plots - UsuniÄ™to wszystkie `plt.show()` - wykresy zapisujÄ… siÄ™ automatycznie

â”œâ”€â”€ visualize_membership_functions.py - **Efekt:** Pipeline wykonuje siÄ™ bez zatrzymywania na oknach!

â”œâ”€â”€ data_exploration.py # EDA visualizations

â”‚2. **ğŸ“¦ Separacja logiki biznesowej**

â”œâ”€â”€ app.py # Streamlit web interface

â”‚ - Utworzono `utils.py` - funkcje Å‚adowania modeli ANFIS i wynikÃ³w

â”œâ”€â”€ models/ # Trained model weights - Utworzono `scaller.py` - centralne zarzÄ…dzanie scalerami

â””â”€â”€ results/ # Generated plots & metrics - **Efekt:** `app.py` zawiera tylko kod UI Streamlit

````

3. **ğŸš« Rozszerzony .gitignore**

---

   - Dodano ignorowanie wygenerowanych plikÃ³w (_.npy, _.h5, _.pkl, _.png)

## ğŸ“Š Results & Visualizations   - **Efekt:** Repozytorium nie zawiera binarnych artefaktÃ³w



The automated pipeline generates:4. **ğŸ“š PeÅ‚na dokumentacja**

   - `CHANGELOG.md` - szczegÃ³Å‚owy opis zmian technicznych

### ANFIS Results (per dataset Ã— MF configuration):   - `PODSUMOWANIE.md` - instrukcje testowania i ocena jakoÅ›ci

- Training curves (accuracy/MAE + loss)

- Prediction scatter plots**KompatybilnoÅ›Ä‡:** Wszystkie zmiany sÄ… wstecznie kompatybilne âœ…

- Membership function plots

- Cross-validation metrics (5-fold)---

- Fuzzy rule extraction (top-K rules)

## ğŸš€ Instrukcja uruchomienia

### Data Exploration:

- Class/target distribution plots### **SZYBKI START** âš¡

- Feature correlation heatmaps

- Feature distribution histogramsProjekt zostaÅ‚ zoptymalizowany do bezproblemowego uruchomienia:

- Pairplots for key features

```bash

### Model Comparison:# 1. Instalacja zaleÅ¼noÅ›ci

- Accuracy/MAE bar chartspip install -r requirements.txt

- Overfitting analysis (train-test gap)

- Performance ranking table# 2. Uruchomienie peÅ‚nego pipeline'u (wszystkie kroki automatycznie)

python main.py

---

# 3. Uruchomienie interfejsu Streamlit

## ğŸ¯ Key Featuresstreamlit run app.py

````

âœ… **Fully Automated**: Single command setup

âœ… **Two Problem Types**: Classification + Regression **Uwaga:** Od wersji 1.1.0 wszystkie wykresy generujÄ… siÄ™ automatycznie do plikÃ³w bez wyÅ›wietlania okien! ğŸ‰

âœ… **Multiple Datasets**: 4 configurations (concrete, all, red, white)

âœ… **Cross-Validation**: 5-fold stratified/standard ---

âœ… **Interactive GUI**: Streamlit web dashboard

âœ… **Rule Extraction**: Interpretable fuzzy rules ### **KROK 1: Eksploracja danych** ğŸ“Š

âœ… **Comprehensive Comparison**: 4 ML algorithms

âœ… **Publication-Ready Plots**: 300 DPI PNG exports```bash

python data_exploration.py

---```

## ğŸ”¬ Technical Details**Co robi ten skrypt:**

### Preprocessing- Pobiera dataset Wine Quality (czerwone i biaÅ‚e wino)

- **Wine**: StandardScaler per dataset variant, 80/20 split- ÅÄ…czy oba datasety (6497 prÃ³bek)

- **Concrete**: StandardScaler, 80/20 split- Analizuje rozkÅ‚ad jakoÅ›ci wina (skala 3-9)

- **ANFIS Input Range**: Normalized to [-3, 3]- Sprawdza braki danych i korelacje miÄ™dzy cechami

- Generuje wykresy:

### Training Configuration - `quality_distribution.png` - rozkÅ‚ad jakoÅ›ci wina

- **Optimizer**: Nadam (lr=0.001) - `correlation_matrix.png` - macierz korelacji cech

- **Epochs**: 20 (early stopping patience=10)

- **Batch Size**: 32**Rezultat:**

- **Loss Functions**:

  - Wine: Binary crossentropy- âœ… Pobrane dane o winie

  - Concrete: Mean Squared Error- âœ… Wygenerowane wykresy analityczne

### Cross-Validation---

- **Wine**: 5-fold Stratified (preserves class balance)

- **Concrete**: 5-fold Standard (regression)### **KROK 2: Przygotowanie danych** ğŸ”„

---```bash

python data_preprocessing.py

## ğŸ“– Documentation```

- **[MANUAL_INSTRUCTION.md](MANUAL_INSTRUCTION.md)**: Detailed step-by-step installation guide**Co robi ten skrypt:**

- **[CHANGES.md](CHANGES.md)**: Project evolution history

- PrzeksztaÅ‚ca problem na klasyfikacjÄ™ binarnÄ…:

--- - **Klasa 0** (zÅ‚a jakoÅ›Ä‡): jakoÅ›Ä‡ â‰¤ 5

- **Klasa 1** (dobra jakoÅ›Ä‡): jakoÅ›Ä‡ > 5

## ğŸ‘¥ Authors- Wybiera 11 najwaÅ¼niejszych cech (fixed acidity, alcohol, pH, itd.)

- Dzieli dane na zbiÃ³r treningowy (80%) i testowy (20%)

- **Dawid Olko** - Project Lead- **Standaryzuje dane** (StandardScaler) - kluczowe dla ANFIS!

- **Piotr SmoÅ‚a** - ML Implementation- Zapisuje przetworzone dane do plikÃ³w `.npy`

- **Jakub Opar** - Data Analysis

- **MichaÅ‚ Pilecki** - Visualization**Rezultat:**

---- âœ… 5197 prÃ³bek treningowych

- âœ… 1300 prÃ³bek testowych

## ğŸ“„ License- âœ… RozkÅ‚ad klas: 2384 zÅ‚ej jakoÅ›ci / 4113 dobrej jakoÅ›ci

This project is licensed under the MIT License - see [LICENSE](LICENSE) for details.---

---### **KROK 3: Trening modeli ANFIS** ğŸ§ 

## ğŸ“š References```bash

python train_anfis.py

1. **ANFIS**: J.-S. R. Jang, "ANFIS: adaptive-network-based fuzzy inference system," IEEE Transactions on Systems, Man, and Cybernetics, vol. 23, no. 3, pp. 665-685, 1993.```

2. **Wine Quality Dataset**: P. Cortez et al., "Modeling wine preferences by data mining from physicochemical properties," Decision Support Systems, 2009.**Co robi ten skrypt:**

3. **Concrete Dataset**: I-C. Yeh, "Modeling of strength of high-performance concrete using artificial neural networks," Cement and Concrete Research, 1998.- Trenuje 2 modele ANFIS:

- **ANFIS z 2 funkcjami przynaleÅ¼noÅ›ci** (2048 reguÅ‚)

--- - **ANFIS z 3 funkcjami przynaleÅ¼noÅ›ci** (177,147 reguÅ‚)

- KaÅ¼dy model trenuje siÄ™ przez 20 epok

## ğŸ› Troubleshooting- UÅ¼ywa optymalizatora NADAM + binary crossentropy

- Zapisuje najlepsze wagi modelu (ModelCheckpoint)

**Issue**: Streamlit doesn't launch automatically - Early stopping po 15 epokach bez poprawy

**Solution**: Manually run `streamlit run app.py` after setup completes- Generuje wykresy treningu dla kaÅ¼dego modelu

**Issue**: TensorFlow installation fails **Warstwy modelu ANFIS:**

**Solution**: Ensure Python 3.8-3.12. TensorFlow 2.17 not compatible with 3.13+

1. **FuzzyLayer** - fuzzyfikacja (gaussowska funkcja przynaleÅ¼noÅ›ci)

**Issue**: Out of memory during training 2. **RuleLayer** - generowanie reguÅ‚ rozmytych (AND)

**Solution**: Reduce batch size in `train_anfis.py` (line 95: `batch_size=16`)3. **NormLayer** - normalizacja wag reguÅ‚

4. **DefuzzLayer** - defuzzyfikacja (kombinacja liniowa Takagi-Sugeno)

---5. **SummationLayer** - agregacja wynikÃ³w

## â­ Star This Repo!**Rezultat:**

If this project helped your research or learning, please consider giving it a star â­- âœ… ANFIS (2 funkcje): Test Accuracy = **69.06%**

- âœ… ANFIS (3 funkcje): Test Accuracy = **76.48%**

**Questions?** Open an issue on GitHub!- âœ… Zapisane modele w `models/`

- âœ… Wykresy treningu w `results/`

**Czas wykonania:** ~2 minuty

---

### **KROK 4: Trening modeli porÃ³wnawczych** ğŸ¤–

```bash
python train_comparison_models.py
```

**Co robi ten skrypt:**
Trenuje 3 klasyczne modele uczenia maszynowego:

#### **4.1. Neural Network (NN)**

- Architektura: 16 â†’ Dropout(0.3) â†’ 8 â†’ Dropout(0.2) â†’ 1
- Funkcje aktywacji: ReLU + Sigmoid
- Optymalizator: Adam
- 50 epok z early stopping

#### **4.2. Support Vector Machine (SVM)**

- Kernel: RBF (Radial Basis Function)
- C=1.0, gamma='scale'
- Trenowany na caÅ‚ym zbiorze

#### **4.3. Random Forest**

- 200 drzew decyzyjnych
- max_depth=15
- Trening rÃ³wnolegÅ‚y (n_jobs=-1)

**Rezultat:**

- âœ… Neural Network: Test Accuracy = **75.69%**
- âœ… SVM: Test Accuracy = **77.85%**
- âœ… Random Forest: Test Accuracy = **83.23%** ğŸ†
- âœ… Wszystkie modele zapisane w `models/`

**Czas wykonania:** ~5-10 minut

---

### **KROK 5: PorÃ³wnanie wszystkich modeli** ğŸ“ˆ

```bash
python compare_all_models.py
```

**Co robi ten skrypt:**

- Wczytuje wyniki wszystkich 5 modeli
- Generuje 2 wykresy porÃ³wnawcze:
  - **all_models_comparison.png** - wykres sÅ‚upkowy Train vs Test
  - **overfitting_analysis.png** - analiza rÃ³Å¼nicy Train-Test
- WyÅ›wietla szczegÃ³Å‚owÄ… tabelÄ™ rankingowÄ…

**Rezultat:**

```
ğŸ¥‡ #1: Random Forest    - 83.23% (ale overfitting: 14.46%)
ğŸ¥ˆ #2: SVM              - 77.85% (minimal overfitting: 1.47%)
ğŸ¥‰ #3: ANFIS (3 funkcje)- 76.48% (lekki overfitting: 4.59%)
   #4: Neural Network   - 75.69% (minimal overfitting: 1.76%)
   #5: ANFIS (2 funkcje)- 69.06% (brak overfittingu: 0.75%)
```

---

## ğŸ“„ Opis plikÃ³w

### **anfis.py**

GÅ‚Ã³wna implementacja algorytmu ANFIS w TensorFlow/Keras.

**Klasy:**

- `ANFISModel` - gÅ‚Ã³wny model ANFIS
- `FuzzyLayer` - warstwa fuzzyfikacji z gaussowskimi funkcjami przynaleÅ¼noÅ›ci
- `RuleLayer` - warstwa reguÅ‚ rozmytych (T-norma = mnoÅ¼enie)
- `NormLayer` - normalizacja wag reguÅ‚
- `DefuzzLayer` - defuzzyfikacja metodÄ… Takagi-Sugeno-Kanga
- `SummationLayer` - agregacja koÅ„cowa

**Kluczowe funkcje:**

- `fit()` - trenowanie modelu
- `get_membership_functions()` - zwraca wyuczone parametry funkcji przynaleÅ¼noÅ›ci

---

### **utils.py** ğŸ†•

ModuÅ‚ pomocniczy z logikÄ… biznesowÄ… (v1.1.0).

**Funkcje:**

- `load_anfis_model(weights_path)` - Å‚aduje model ANFIS z pliku H5
  - Automatycznie wykrywa liczbÄ™ wejÅ›Ä‡ i funkcji przynaleÅ¼noÅ›ci
  - ObsÅ‚uguje pliki `.weights.h5`
- `load_results()` - agreguje wyniki wszystkich 5 modeli z JSON
  - Zwraca sÅ‚ownik z metrykami Train/Test Accuracy

---

### **scaller.py** ğŸ†•

ModuÅ‚ zarzÄ…dzajÄ…cy scalerami danych (v1.1.0).

**Funkcje:**

- `load_scalers()` - Å‚aduje oba scalery (11D i 12D)
- `get_scaler_11d()` - zwraca scaler dla ANFIS (11 cech)
- `get_scaler_12d()` - zwraca scaler dla NN/SVM/RF (12 cech z wine_type)

---

### **data_exploration.py**

Skrypt do analizy eksploracyjnej danych Wine Quality.

**Funkcje:**

- Pobieranie danych z UCI ML Repository
- Statystyki opisowe (mean, std, min, max)
- Sprawdzanie brakÃ³w danych
- Wizualizacja rozkÅ‚adu jakoÅ›ci wina
- Macierz korelacji Pearsona

**Zmiany v1.1.0:**

- âœ… Dodano `matplotlib.use('Agg')` - bez wyÅ›wietlania okien
- âœ… UsuniÄ™to `plt.show()` - automatyczny zapis do plikÃ³w

---

### **data_preprocessing.py**

Przygotowanie danych do treningu.

**Funkcje:**

- `load_and_preprocess_data()` - gÅ‚Ã³wna funkcja przetwarzania
  - ÅÄ…czenie red + white wine
  - Binaryzacja etykiet (quality > 5)
  - Selekcja 11 cech
  - PodziaÅ‚ train/test (80/20, stratified)
  - Standaryzacja (StandardScaler)
  - Zapis do `.npy`

---

### **train_anfis.py**

Trening modeli ANFIS z rÃ³Å¼nÄ… liczbÄ… funkcji przynaleÅ¼noÅ›ci.

**Funkcje:**

- `train_anfis_model(n_memb, epochs, batch_size)` - trenuje jeden model ANFIS
- `plot_training_history(history, n_memb)` - wizualizacja treningu

**Parametry:**

- `n_memb` - liczba funkcji przynaleÅ¼noÅ›ci (2 lub 3)
- `epochs` - liczba epok (domyÅ›lnie 20)
- `batch_size` - rozmiar batcha (32)

**Zmiany v1.1.0:**

- âœ… Dodano `matplotlib.use('Agg')`
- âœ… `plot_training_history()` zapisuje zamiast wyÅ›wietlaÄ‡

---

### **train_comparison_models.py**

Trening modeli porÃ³wnawczych (NN, SVM, RF).

**Funkcje:**

- `train_neural_network()` - trenuje klasycznÄ… sieÄ‡ neuronowÄ…
- `train_svm()` - trenuje SVM z RBF kernel
- `train_random_forest()` - trenuje Random Forest
- `plot_training_history()` - wykresy dla NN

**Zmiany v1.1.0:**

- âœ… Dodano `matplotlib.use('Agg')`

---

### **compare_all_models.py**

PorÃ³wnanie i wizualizacja wynikÃ³w wszystkich modeli.

**Funkcje:**

- `load_all_results()` - wczytuje wyniki z plikÃ³w JSON
- `plot_comparison_bar_chart()` - wykres sÅ‚upkowy
- `plot_overfitting_analysis()` - analiza overfittingu
- `create_summary_table()` - tabela rankingowa

**Zmiany v1.1.0:**

- âœ… UsuniÄ™to `plt.show()` z dwÃ³ch funkcji wykresÃ³w

---

### **visualize_membership_functions.py**

Wizualizacja wyuczonych funkcji przynaleÅ¼noÅ›ci ANFIS.

**Funkcje:**

- Åadowanie wag modelu ANFIS
- Wykresy gaussowskich funkcji dla 6 najwaÅ¼niejszych cech
- Zapis do `membership_functions_visualization.png`

**Zmiany v1.1.0:**

- âœ… Dodano `matplotlib.use('Agg')`

---

### **app.py**

Interfejs uÅ¼ytkownika Streamlit (w trakcie rekonstrukcji).

**Strony:**

- ğŸ  Strona gÅ‚Ã³wna - statystyki projektu
- ğŸ“Š Wyniki modeli - porÃ³wnanie i ranking
- ğŸ§  ANFIS - teoria i wizualizacje
- ğŸ“ˆ Eksploracja danych - podglÄ…d datasetu
- ğŸ· Predykcja - interaktywne przewidywanie jakoÅ›ci wina

**Zmiany v1.1.0:**

- âœ… Przeniesiono logikÄ™ do `utils.py` i `scaller.py`
- âš ï¸ Wymaga peÅ‚nej rekonstrukcji funkcjonalnoÅ›ci

---

### **main.py**

GÅ‚Ã³wny pipeline wykonujÄ…cy wszystkie kroki automatycznie.

**KolejnoÅ›Ä‡ wykonania:**

1. data_preprocessing.py â† Przygotowanie danych
2. train_anfis.py â† Trening modeli ANFIS
3. visualize_membership_functions.py â† Wizualizacja funkcji przynaleÅ¼noÅ›ci
4. train_comparison_models.py â† Trening modeli porÃ³wnawczych (NN, SVM, RF)
5. data_exploration.py â† Analiza eksploracyjna danych
6. compare_all_models.py â† PorÃ³wnanie wszystkich modeli
7. app.py â† Uruchomienie GUI Streamlit

---

## ğŸ“Š Wyniki

### Finalne porÃ³wnanie modeli:

| Ranking | Model             | Test Accuracy | Train Accuracy | Overfitting | Interpretacja          |
| ------- | ----------------- | ------------- | -------------- | ----------- | ---------------------- |
| ğŸ¥‡      | Random Forest     | **83.23%**    | 97.69%         | 14.46% âš ï¸   | âŒ Czarna skrzynka     |
| ğŸ¥ˆ      | SVM               | **77.85%**    | 79.31%         | 1.47% âœ…    | âŒ Czarna skrzynka     |
| ğŸ¥‰      | ANFIS (3 funkcje) | **76.48%**    | 81.08%         | 4.59% âœ…    | âœ… **ReguÅ‚y rozmyte!** |
| 4       | Neural Network    | **75.69%**    | 77.45%         | 1.76% âœ…    | âŒ Czarna skrzynka     |
| 5       | ANFIS (2 funkcje) | **69.06%**    | 69.81%         | 0.75% âœ…    | âœ… **ReguÅ‚y rozmyte!** |

### Kluczowe obserwacje:

âœ… **ANFIS jest konkurencyjny!**

- ANFIS (3 funkcje) osiÄ…ga 76.48% - tylko 6.75% gorszy od najlepszego modelu
- Lepszy niÅ¼ klasyczna sieÄ‡ neuronowa (75.69%)
- Minimalny overfitting (4.59%)

âœ… **ANFIS ma INTERPRETACJÄ˜!**

- MoÅ¼emy zobaczyÄ‡ wyuczone funkcje przynaleÅ¼noÅ›ci
- MoÅ¼emy zidentyfikowaÄ‡ najwaÅ¼niejsze reguÅ‚y rozmyte
- Inne modele to "czarne skrzynki"

âš ï¸ **Random Forest overfituje**

- NajwyÅ¼sza dokÅ‚adnoÅ›Ä‡ testowa (83.23%)
- Ale ogromny overfitting (14.46%)
- Train accuracy = 97.69% (prawie idealne dopasowanie do danych treningowych)

---

## ğŸ”¬ Elementy logiki rozmytej w ANFIS

### Gaussowska funkcja przynaleÅ¼noÅ›ci:

```
Î¼(x) = exp(-(x - c)Â² / 2ÏƒÂ²)
```

gdzie:

- `c` - centrum funkcji (uczone)
- `Ïƒ` - szerokoÅ›Ä‡ funkcji (uczone)

### ReguÅ‚y rozmyte (przykÅ‚ad):

```
JEÅšLI alkohol jest WYSOKI AND kwasowoÅ›Ä‡ jest NISKA
TO jakoÅ›Ä‡ wina jest DOBRA
```

### Defuzzyfikacja (Takagi-Sugeno):

```
WyjÅ›cie = Î£(wáµ¢ Ã— (aáµ¢xâ‚ + báµ¢xâ‚‚ + ... + cáµ¢))
```

gdzie `wáµ¢` to znormalizowane wagi reguÅ‚

---

## ğŸ“ Wnioski

1. **ANFIS Å‚Ä…czy zalety dwÃ³ch Å›wiatÃ³w:**

   - Uczenie siÄ™ jak sieÄ‡ neuronowa
   - Interpretacja jak system ekspercki

2. **3 funkcje przynaleÅ¼noÅ›ci >> 2 funkcje:**

   - +7.42% dokÅ‚adnoÅ›ci (76.48% vs 69.06%)
   - WiÄ™cej reguÅ‚ = lepsza reprezentacja danych

3. **ANFIS vs Klasyczne modele:**

   - Random Forest najlepszy, ale overfituje
   - SVM solidny wybÃ³r (77.85%, minimalny overfitting)
   - **ANFIS Å›wietny kompromis:** dobra dokÅ‚adnoÅ›Ä‡ + interpretowalnoÅ›Ä‡

4. **Problem jakoÅ›ci wina:**
   - 11 cech numerycznych, 6497 prÃ³bek
   - Niezbalansowanie klas (37% zÅ‚ej / 63% dobrej jakoÅ›ci)
   - Wszystkie modele osiÄ…gajÄ… >75% dokÅ‚adnoÅ›ci

---

## ğŸ“ Autor

**Dawid Olko, Piotr SmoÅ‚a, Jakub Opar, MichaÅ‚ Pilecki**  
Kierunek: Informatyka, grupa Lab 01  
Przedmiot: Systemy rozmyte  
ProwadzÄ…cy: mgr inÅ¼. Marcin Mrukowicz  
RzeszÃ³w, r.a. 2025/2026

---

## ğŸ“š Bibliografia

1. Jang, J-S. R. (1993). ANFIS: adaptive-network-based fuzzy inference system. IEEE Transactions on Systems, Man, and Cybernetics.
2. Implementacja bazowa: [Gregor Lenhard - ANFIS TensorFlow 2.0](https://github.com/gregorLen/AnfisTensorflow2.0)
3. Dataset: [UCI ML Repository - Wine Quality Dataset](https://archive.ics.uci.edu/dataset/186/wine+quality)

---

**âœ… Projekt gotowy do uruchomienia!**  
PostÄ™puj zgodnie z instrukcjÄ… krok po kroku (KROK 1-5) aby odtworzyÄ‡ wszystkie wyniki.

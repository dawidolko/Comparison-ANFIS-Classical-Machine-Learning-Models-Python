# ğŸ“š README - Projekt: Klasyfikacja JakoÅ›ci Wina za pomocÄ… ANFIS

## ğŸ“‹ Spis treÅ›ci

1. [Opis projektu](#opis-projektu)
2. [Struktura projektu](#struktura-projektu)
3. [Wymagania](#wymagania)
4. [Instrukcja uruchomienia](#instrukcja-uruchomienia)
5. [Opis plikÃ³w](#opis-plikÃ³w)
6. [Wyniki](#wyniki)

---

## ğŸ¯ Opis projektu

Projekt porÃ³wnuje algorytm **ANFIS (Adaptive Neuro-Fuzzy Inference System)** z klasycznymi metodami uczenia maszynowego w zadaniu klasyfikacji jakoÅ›ci wina. ANFIS to hybrydowy model Å‚Ä…czÄ…cy:

- **LogikÄ™ rozmytÄ…** - interpretowalne reguÅ‚y IF-THEN
- **Sieci neuronowe** - uczenie parametrÃ³w za pomocÄ… propagacji wstecznej

### GÅ‚Ã³wne cele:

âœ… Implementacja algorytmu ANFIS w TensorFlow/Keras  
âœ… PorÃ³wnanie ANFIS z klasycznymi modelami (NN, SVM, Random Forest)  
âœ… Analiza interpretowalnoÅ›ci modelu rozmytego  
âœ… Wizualizacja wyuczonych funkcji przynaleÅ¼noÅ›ci

---

## ğŸ“ Struktura projektu

```
wine_quality_anfis/
â”œâ”€â”€ data/                          # Dane (generowane automatycznie)
â”‚   â”œâ”€â”€ winequality-red.csv        # Dataset wina czerwonego
â”‚   â”œâ”€â”€ winequality-white.csv      # Dataset wina biaÅ‚ego
â”‚   â”œâ”€â”€ winequality.names          # Opis datasetu
â”‚   â”œâ”€â”€ X_train.npy               # (generowane)
â”‚   â”œâ”€â”€ X_test.npy                # (generowane)
â”‚   â”œâ”€â”€ y_train.npy               # (generowane)
â”‚   â””â”€â”€ y_test.npy                # (generowane)
â”œâ”€â”€ models/                        # Wytrenowane modele (generowane)
â”‚   â”œâ”€â”€ anfis_best_2memb.weights.h5
â”‚   â”œâ”€â”€ anfis_best_3memb.weights.h5
â”‚   â”œâ”€â”€ nn_best.keras
â”‚   â”œâ”€â”€ svm_model.pkl
â”‚   â”œâ”€â”€ rf_model.pkl
â”‚   â”œâ”€â”€ scaler.pkl                # Scaler dla ANFIS (11 cech)
â”‚   â””â”€â”€ scaler_nn.pkl             # Scaler dla NN/SVM/RF (12 cech)
â”œâ”€â”€ results/                       # Wykresy i wyniki (generowane)
â”‚   â”œâ”€â”€ all_models_comparison.png
â”‚   â”œâ”€â”€ overfitting_analysis.png
â”‚   â”œâ”€â”€ anfis_2memb_training.png
â”‚   â”œâ”€â”€ anfis_3memb_training.png
â”‚   â”œâ”€â”€ membership_functions_visualization.png
â”‚   â””â”€â”€ *.json (wyniki liczbowe)
â”œâ”€â”€ anfis.py                       # âš™ï¸ Implementacja ANFIS
â”œâ”€â”€ data_exploration.py            # ğŸ“Š Eksploracja danych
â”œâ”€â”€ data_preprocessing.py          # ğŸ”„ Przygotowanie danych
â”œâ”€â”€ train_anfis.py                 # ğŸ§  Trening modeli ANFIS
â”œâ”€â”€ train_comparison_models.py     # ğŸ¤– Trening modeli porÃ³wnawczych
â”œâ”€â”€ compare_all_models.py          # ğŸ“ˆ PorÃ³wnanie wynikÃ³w
â”œâ”€â”€ visualize_membership_functions.py  # ğŸ“‰ Wizualizacja funkcji przynaleÅ¼noÅ›ci
â”œâ”€â”€ utils.py                       # ğŸ› ï¸ Funkcje pomocnicze (NOWE v1.1.0)
â”œâ”€â”€ scaller.py                     # ğŸ“ Åadowanie scalerÃ³w (NOWE v1.1.0)
â”œâ”€â”€ app.py                         # ğŸ· Interfejs Streamlit
â”œâ”€â”€ main.py                        # ğŸš€ GÅ‚Ã³wny pipeline
â”œâ”€â”€ requirements.txt               # ğŸ“¦ ZaleÅ¼noÅ›ci
â””â”€â”€ .gitignore                     # ğŸš« Pliki ignorowane przez Git
```

**Legenda:**

- ğŸ“ Foldery generowane automatycznie podczas uruchomienia
- ğŸ†• **NOWE w v1.1.0:** ModuÅ‚y `utils.py` i `scaller.py` do separacji logiki biznesowej

---

## ğŸ”§ Wymagania

### Wymagane biblioteki:

```
tensorflow==2.17.0
numpy==1.26.4
pandas==2.2.3
scikit-learn==1.5.2
matplotlib==3.9.2
seaborn==0.12.2
streamlit==1.39.0
h5py==3.12.1
pillow==11.0.0
```

### Instalacja:

```bash
pip install -r requirements.txt
```

### Automatyczne skrypty setup:

```bash
# Windows
setup.bat

# Linux/macOS
chmod +x setup.sh
./setup.sh
```

---

## ğŸ†• Zmiany w wersji 1.1.0

### âœ… Optymalizacje wykonane:

1. **ğŸ–¼ï¸ Naprawiono blokowanie przez matplotlib**

   - Dodano `matplotlib.use('Agg')` do wszystkich skryptÃ³w
   - UsuniÄ™to wszystkie `plt.show()` - wykresy zapisujÄ… siÄ™ automatycznie
   - **Efekt:** Pipeline wykonuje siÄ™ bez zatrzymywania na oknach!

2. **ğŸ“¦ Separacja logiki biznesowej**

   - Utworzono `utils.py` - funkcje Å‚adowania modeli ANFIS i wynikÃ³w
   - Utworzono `scaller.py` - centralne zarzÄ…dzanie scalerami
   - **Efekt:** `app.py` zawiera tylko kod UI Streamlit

3. **ğŸš« Rozszerzony .gitignore**

   - Dodano ignorowanie wygenerowanych plikÃ³w (_.npy, _.h5, _.pkl, _.png)
   - **Efekt:** Repozytorium nie zawiera binarnych artefaktÃ³w

4. **ğŸ“š PeÅ‚na dokumentacja**
   - `CHANGELOG.md` - szczegÃ³Å‚owy opis zmian technicznych
   - `PODSUMOWANIE.md` - instrukcje testowania i ocena jakoÅ›ci

**KompatybilnoÅ›Ä‡:** Wszystkie zmiany sÄ… wstecznie kompatybilne âœ…

---

## ğŸš€ Instrukcja uruchomienia

### **SZYBKI START** âš¡

Projekt zostaÅ‚ zoptymalizowany do bezproblemowego uruchomienia:

```bash
# 1. Instalacja zaleÅ¼noÅ›ci
pip install -r requirements.txt

# 2. Uruchomienie peÅ‚nego pipeline'u (wszystkie kroki automatycznie)
python main.py

# 3. Uruchomienie interfejsu Streamlit
streamlit run app.py
```

**Uwaga:** Od wersji 1.1.0 wszystkie wykresy generujÄ… siÄ™ automatycznie do plikÃ³w bez wyÅ›wietlania okien! ğŸ‰

---

### **KROK 1: Eksploracja danych** ğŸ“Š

```bash
python data_exploration.py
```

**Co robi ten skrypt:**

- Pobiera dataset Wine Quality (czerwone i biaÅ‚e wino)
- ÅÄ…czy oba datasety (6497 prÃ³bek)
- Analizuje rozkÅ‚ad jakoÅ›ci wina (skala 3-9)
- Sprawdza braki danych i korelacje miÄ™dzy cechami
- Generuje wykresy:
  - `quality_distribution.png` - rozkÅ‚ad jakoÅ›ci wina
  - `correlation_matrix.png` - macierz korelacji cech

**Rezultat:**

- âœ… Pobrane dane o winie
- âœ… Wygenerowane wykresy analityczne

---

### **KROK 2: Przygotowanie danych** ğŸ”„

```bash
python data_preprocessing.py
```

**Co robi ten skrypt:**

- PrzeksztaÅ‚ca problem na klasyfikacjÄ™ binarnÄ…:
  - **Klasa 0** (zÅ‚a jakoÅ›Ä‡): jakoÅ›Ä‡ â‰¤ 5
  - **Klasa 1** (dobra jakoÅ›Ä‡): jakoÅ›Ä‡ > 5
- Wybiera 11 najwaÅ¼niejszych cech (fixed acidity, alcohol, pH, itd.)
- Dzieli dane na zbiÃ³r treningowy (80%) i testowy (20%)
- **Standaryzuje dane** (StandardScaler) - kluczowe dla ANFIS!
- Zapisuje przetworzone dane do plikÃ³w `.npy`

**Rezultat:**

- âœ… 5197 prÃ³bek treningowych
- âœ… 1300 prÃ³bek testowych
- âœ… RozkÅ‚ad klas: 2384 zÅ‚ej jakoÅ›ci / 4113 dobrej jakoÅ›ci

---

### **KROK 3: Trening modeli ANFIS** ğŸ§ 

```bash
python train_anfis.py
```

**Co robi ten skrypt:**

- Trenuje 2 modele ANFIS:
  - **ANFIS z 2 funkcjami przynaleÅ¼noÅ›ci** (2048 reguÅ‚)
  - **ANFIS z 3 funkcjami przynaleÅ¼noÅ›ci** (177,147 reguÅ‚)
- KaÅ¼dy model trenuje siÄ™ przez 20 epok
- UÅ¼ywa optymalizatora NADAM + binary crossentropy
- Zapisuje najlepsze wagi modelu (ModelCheckpoint)
- Early stopping po 15 epokach bez poprawy
- Generuje wykresy treningu dla kaÅ¼dego modelu

**Warstwy modelu ANFIS:**

1. **FuzzyLayer** - fuzzyfikacja (gaussowska funkcja przynaleÅ¼noÅ›ci)
2. **RuleLayer** - generowanie reguÅ‚ rozmytych (AND)
3. **NormLayer** - normalizacja wag reguÅ‚
4. **DefuzzLayer** - defuzzyfikacja (kombinacja liniowa Takagi-Sugeno)
5. **SummationLayer** - agregacja wynikÃ³w

**Rezultat:**

- âœ… ANFIS (2 funkcje): Test Accuracy = **69.06%**
- âœ… ANFIS (3 funkcje): Test Accuracy = **76.48%**
- âœ… Zapisane modele w `models/`
- âœ… Wykresy treningu w `results/`

**Czas wykonania:** ~2 minuty

---

### **KROK 4: Trening modeli porÃ³wnawczych** ğŸ¤–

```bash
python train_comparison_models.py
```

**Co robi ten skrypt:**
Trenuje 3 klasyczne modele uczenia maszynowego:

#### **4.1. Neural Network (NN)**

- Architektura: 16 â†’ Dropout(0.3) â†’ 8 â†’ Dropout(0.2) â†’ 1
- Funkcje aktywacji: ReLU + Sigmoid
- Optymalizator: Adam
- 50 epok z early stopping

#### **4.2. Support Vector Machine (SVM)**

- Kernel: RBF (Radial Basis Function)
- C=1.0, gamma='scale'
- Trenowany na caÅ‚ym zbiorze

#### **4.3. Random Forest**

- 200 drzew decyzyjnych
- max_depth=15
- Trening rÃ³wnolegÅ‚y (n_jobs=-1)

**Rezultat:**

- âœ… Neural Network: Test Accuracy = **75.69%**
- âœ… SVM: Test Accuracy = **77.85%**
- âœ… Random Forest: Test Accuracy = **83.23%** ğŸ†
- âœ… Wszystkie modele zapisane w `models/`

**Czas wykonania:** ~5-10 minut

---

### **KROK 5: PorÃ³wnanie wszystkich modeli** ğŸ“ˆ

```bash
python compare_all_models.py
```

**Co robi ten skrypt:**

- Wczytuje wyniki wszystkich 5 modeli
- Generuje 2 wykresy porÃ³wnawcze:
  - **all_models_comparison.png** - wykres sÅ‚upkowy Train vs Test
  - **overfitting_analysis.png** - analiza rÃ³Å¼nicy Train-Test
- WyÅ›wietla szczegÃ³Å‚owÄ… tabelÄ™ rankingowÄ…

**Rezultat:**

```
ğŸ¥‡ #1: Random Forest    - 83.23% (ale overfitting: 14.46%)
ğŸ¥ˆ #2: SVM              - 77.85% (minimal overfitting: 1.47%)
ğŸ¥‰ #3: ANFIS (3 funkcje)- 76.48% (lekki overfitting: 4.59%)
   #4: Neural Network   - 75.69% (minimal overfitting: 1.76%)
   #5: ANFIS (2 funkcje)- 69.06% (brak overfittingu: 0.75%)
```

---

## ğŸ“„ Opis plikÃ³w

### **anfis.py**

GÅ‚Ã³wna implementacja algorytmu ANFIS w TensorFlow/Keras.

**Klasy:**

- `ANFISModel` - gÅ‚Ã³wny model ANFIS
- `FuzzyLayer` - warstwa fuzzyfikacji z gaussowskimi funkcjami przynaleÅ¼noÅ›ci
- `RuleLayer` - warstwa reguÅ‚ rozmytych (T-norma = mnoÅ¼enie)
- `NormLayer` - normalizacja wag reguÅ‚
- `DefuzzLayer` - defuzzyfikacja metodÄ… Takagi-Sugeno-Kanga
- `SummationLayer` - agregacja koÅ„cowa

**Kluczowe funkcje:**

- `fit()` - trenowanie modelu
- `get_membership_functions()` - zwraca wyuczone parametry funkcji przynaleÅ¼noÅ›ci

---

### **utils.py** ğŸ†•

ModuÅ‚ pomocniczy z logikÄ… biznesowÄ… (v1.1.0).

**Funkcje:**

- `load_anfis_model(weights_path)` - Å‚aduje model ANFIS z pliku H5
  - Automatycznie wykrywa liczbÄ™ wejÅ›Ä‡ i funkcji przynaleÅ¼noÅ›ci
  - ObsÅ‚uguje pliki `.weights.h5`
- `load_results()` - agreguje wyniki wszystkich 5 modeli z JSON
  - Zwraca sÅ‚ownik z metrykami Train/Test Accuracy

---

### **scaller.py** ğŸ†•

ModuÅ‚ zarzÄ…dzajÄ…cy scalerami danych (v1.1.0).

**Funkcje:**

- `load_scalers()` - Å‚aduje oba scalery (11D i 12D)
- `get_scaler_11d()` - zwraca scaler dla ANFIS (11 cech)
- `get_scaler_12d()` - zwraca scaler dla NN/SVM/RF (12 cech z wine_type)

---

### **data_exploration.py**

Skrypt do analizy eksploracyjnej danych Wine Quality.

**Funkcje:**

- Pobieranie danych z UCI ML Repository
- Statystyki opisowe (mean, std, min, max)
- Sprawdzanie brakÃ³w danych
- Wizualizacja rozkÅ‚adu jakoÅ›ci wina
- Macierz korelacji Pearsona

**Zmiany v1.1.0:**

- âœ… Dodano `matplotlib.use('Agg')` - bez wyÅ›wietlania okien
- âœ… UsuniÄ™to `plt.show()` - automatyczny zapis do plikÃ³w

---

### **data_preprocessing.py**

Przygotowanie danych do treningu.

**Funkcje:**

- `load_and_preprocess_data()` - gÅ‚Ã³wna funkcja przetwarzania
  - ÅÄ…czenie red + white wine
  - Binaryzacja etykiet (quality > 5)
  - Selekcja 11 cech
  - PodziaÅ‚ train/test (80/20, stratified)
  - Standaryzacja (StandardScaler)
  - Zapis do `.npy`

---

### **train_anfis.py**

Trening modeli ANFIS z rÃ³Å¼nÄ… liczbÄ… funkcji przynaleÅ¼noÅ›ci.

**Funkcje:**

- `train_anfis_model(n_memb, epochs, batch_size)` - trenuje jeden model ANFIS
- `plot_training_history(history, n_memb)` - wizualizacja treningu

**Parametry:**

- `n_memb` - liczba funkcji przynaleÅ¼noÅ›ci (2 lub 3)
- `epochs` - liczba epok (domyÅ›lnie 20)
- `batch_size` - rozmiar batcha (32)

**Zmiany v1.1.0:**

- âœ… Dodano `matplotlib.use('Agg')`
- âœ… `plot_training_history()` zapisuje zamiast wyÅ›wietlaÄ‡

---

### **train_comparison_models.py**

Trening modeli porÃ³wnawczych (NN, SVM, RF).

**Funkcje:**

- `train_neural_network()` - trenuje klasycznÄ… sieÄ‡ neuronowÄ…
- `train_svm()` - trenuje SVM z RBF kernel
- `train_random_forest()` - trenuje Random Forest
- `plot_training_history()` - wykresy dla NN

**Zmiany v1.1.0:**

- âœ… Dodano `matplotlib.use('Agg')`

---

### **compare_all_models.py**

PorÃ³wnanie i wizualizacja wynikÃ³w wszystkich modeli.

**Funkcje:**

- `load_all_results()` - wczytuje wyniki z plikÃ³w JSON
- `plot_comparison_bar_chart()` - wykres sÅ‚upkowy
- `plot_overfitting_analysis()` - analiza overfittingu
- `create_summary_table()` - tabela rankingowa

**Zmiany v1.1.0:**

- âœ… UsuniÄ™to `plt.show()` z dwÃ³ch funkcji wykresÃ³w

---

### **visualize_membership_functions.py**

Wizualizacja wyuczonych funkcji przynaleÅ¼noÅ›ci ANFIS.

**Funkcje:**

- Åadowanie wag modelu ANFIS
- Wykresy gaussowskich funkcji dla 6 najwaÅ¼niejszych cech
- Zapis do `membership_functions_visualization.png`

**Zmiany v1.1.0:**

- âœ… Dodano `matplotlib.use('Agg')`

---

### **app.py**

Interfejs uÅ¼ytkownika Streamlit (w trakcie rekonstrukcji).

**Strony:**

- ğŸ  Strona gÅ‚Ã³wna - statystyki projektu
- ğŸ“Š Wyniki modeli - porÃ³wnanie i ranking
- ğŸ§  ANFIS - teoria i wizualizacje
- ğŸ“ˆ Eksploracja danych - podglÄ…d datasetu
- ğŸ· Predykcja - interaktywne przewidywanie jakoÅ›ci wina

**Zmiany v1.1.0:**

- âœ… Przeniesiono logikÄ™ do `utils.py` i `scaller.py`
- âš ï¸ Wymaga peÅ‚nej rekonstrukcji funkcjonalnoÅ›ci

---

### **main.py**

GÅ‚Ã³wny pipeline wykonujÄ…cy wszystkie kroki automatycznie.

**KolejnoÅ›Ä‡ wykonania:**

1. `data_exploration.py` - analiza danych
2. `data_preprocessing.py` - przygotowanie danych
3. `train_anfis.py` - trening ANFIS
4. `train_comparison_models.py` - trening NN/SVM/RF
5. `compare_all_models.py` - porÃ³wnanie wynikÃ³w
6. `visualize_membership_functions.py` - wizualizacja funkcji przynaleÅ¼noÅ›ci

---

## ğŸ“Š Wyniki

### Finalne porÃ³wnanie modeli:

| Ranking | Model             | Test Accuracy | Train Accuracy | Overfitting | Interpretacja          |
| ------- | ----------------- | ------------- | -------------- | ----------- | ---------------------- |
| ğŸ¥‡      | Random Forest     | **83.23%**    | 97.69%         | 14.46% âš ï¸   | âŒ Czarna skrzynka     |
| ğŸ¥ˆ      | SVM               | **77.85%**    | 79.31%         | 1.47% âœ…    | âŒ Czarna skrzynka     |
| ğŸ¥‰      | ANFIS (3 funkcje) | **76.48%**    | 81.08%         | 4.59% âœ…    | âœ… **ReguÅ‚y rozmyte!** |
| 4       | Neural Network    | **75.69%**    | 77.45%         | 1.76% âœ…    | âŒ Czarna skrzynka     |
| 5       | ANFIS (2 funkcje) | **69.06%**    | 69.81%         | 0.75% âœ…    | âœ… **ReguÅ‚y rozmyte!** |

### Kluczowe obserwacje:

âœ… **ANFIS jest konkurencyjny!**

- ANFIS (3 funkcje) osiÄ…ga 76.48% - tylko 6.75% gorszy od najlepszego modelu
- Lepszy niÅ¼ klasyczna sieÄ‡ neuronowa (75.69%)
- Minimalny overfitting (4.59%)

âœ… **ANFIS ma INTERPRETACJÄ˜!**

- MoÅ¼emy zobaczyÄ‡ wyuczone funkcje przynaleÅ¼noÅ›ci
- MoÅ¼emy zidentyfikowaÄ‡ najwaÅ¼niejsze reguÅ‚y rozmyte
- Inne modele to "czarne skrzynki"

âš ï¸ **Random Forest overfituje**

- NajwyÅ¼sza dokÅ‚adnoÅ›Ä‡ testowa (83.23%)
- Ale ogromny overfitting (14.46%)
- Train accuracy = 97.69% (prawie idealne dopasowanie do danych treningowych)

---

## ğŸ”¬ Elementy logiki rozmytej w ANFIS

### Gaussowska funkcja przynaleÅ¼noÅ›ci:

```
Î¼(x) = exp(-(x - c)Â² / 2ÏƒÂ²)
```

gdzie:

- `c` - centrum funkcji (uczone)
- `Ïƒ` - szerokoÅ›Ä‡ funkcji (uczone)

### ReguÅ‚y rozmyte (przykÅ‚ad):

```
JEÅšLI alkohol jest WYSOKI AND kwasowoÅ›Ä‡ jest NISKA
TO jakoÅ›Ä‡ wina jest DOBRA
```

### Defuzzyfikacja (Takagi-Sugeno):

```
WyjÅ›cie = Î£(wáµ¢ Ã— (aáµ¢xâ‚ + báµ¢xâ‚‚ + ... + cáµ¢))
```

gdzie `wáµ¢` to znormalizowane wagi reguÅ‚

---

## ğŸ“ Wnioski

1. **ANFIS Å‚Ä…czy zalety dwÃ³ch Å›wiatÃ³w:**

   - Uczenie siÄ™ jak sieÄ‡ neuronowa
   - Interpretacja jak system ekspercki

2. **3 funkcje przynaleÅ¼noÅ›ci >> 2 funkcje:**

   - +7.42% dokÅ‚adnoÅ›ci (76.48% vs 69.06%)
   - WiÄ™cej reguÅ‚ = lepsza reprezentacja danych

3. **ANFIS vs Klasyczne modele:**

   - Random Forest najlepszy, ale overfituje
   - SVM solidny wybÃ³r (77.85%, minimalny overfitting)
   - **ANFIS Å›wietny kompromis:** dobra dokÅ‚adnoÅ›Ä‡ + interpretowalnoÅ›Ä‡

4. **Problem jakoÅ›ci wina:**
   - 11 cech numerycznych, 6497 prÃ³bek
   - Niezbalansowanie klas (37% zÅ‚ej / 63% dobrej jakoÅ›ci)
   - Wszystkie modele osiÄ…gajÄ… >75% dokÅ‚adnoÅ›ci

---

## ğŸ“ Autor

**Dawid Olko, Piotr SmoÅ‚a, Jakub Opar, MichaÅ‚ Pilecki**  
Kierunek: Informatyka, grupa Lab 01  
Przedmiot: Systemy rozmyte  
ProwadzÄ…cy: mgr inÅ¼. Marcin Mrukowicz  
RzeszÃ³w, r.a. 2025/2026

---

## ğŸ“š Bibliografia

1. Jang, J-S. R. (1993). ANFIS: adaptive-network-based fuzzy inference system. IEEE Transactions on Systems, Man, and Cybernetics.
2. Implementacja bazowa: [Gregor Lenhard - ANFIS TensorFlow 2.0](https://github.com/gregorLen/AnfisTensorflow2.0)
3. Dataset: [UCI ML Repository - Wine Quality Dataset](https://archive.ics.uci.edu/dataset/186/wine+quality)

---

**âœ… Projekt gotowy do uruchomienia!**  
PostÄ™puj zgodnie z instrukcjÄ… krok po kroku (KROK 1-5) aby odtworzyÄ‡ wszystkie wyniki.
